{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GAN First Attempt.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"IbGl220Tn_aU","colab_type":"text"},"cell_type":"markdown","source":["## GAN Attempt\n","\n","This notebook is modified from the keras repository: https://github.com/BAI-Yeqi/Keras-GAN/blob/master/gan/gan.py\n","\n"]},{"metadata":{"id":"2oSSZPO8pcRe","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"2b5a06b2-b753-4d9e-dcbf-0e1698688a2d","executionInfo":{"status":"ok","timestamp":1521477841582,"user_tz":-480,"elapsed":599,"user":{"displayName":"也淇白","photoUrl":"//lh5.googleusercontent.com/-BKSlzGVuH74/AAAAAAAAAAI/AAAAAAAAAA4/ohUp2uylJAI/s50-c-k-no/photo.jpg","userId":"115711400106378591809"}}},"cell_type":"code","source":["from __future__ import print_function, division\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n","from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","\n","import matplotlib.pyplot as plt\n","\n","import sys\n","\n","import numpy as np"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"yQJ6ED9DD1oi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":34},"outputId":"1e639881-b2f7-4a3c-caf9-dbb241350a16","executionInfo":{"status":"ok","timestamp":1521477849195,"user_tz":-480,"elapsed":6208,"user":{"displayName":"也淇白","photoUrl":"//lh5.googleusercontent.com/-BKSlzGVuH74/AAAAAAAAAAI/AAAAAAAAAA4/ohUp2uylJAI/s50-c-k-no/photo.jpg","userId":"115711400106378591809"}}},"cell_type":"code","source":["X_try = np.load(\"drive/Colab Notebooks/Data/ChestX_8/image_array_batch_0.npy\")\n","X_try.shape"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(128, 256, 256)"]},"metadata":{"tags":[]},"execution_count":6}]},{"metadata":{"id":"t5qKSt5uG8z-","colab_type":"text"},"cell_type":"markdown","source":["The Training Set of MNIST got the shape \n","\n","```\n","(60000, 28, 28)\n","```\n","\n"]},{"metadata":{"id":"XXby8MI0oQlo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":2}],"base_uri":"https://localhost:8080/","height":1508},"outputId":"4fe95631-5ed7-48c1-fbe5-fe220cb7cd81"},"cell_type":"code","source":["class GAN():\n","    def __init__(self):\n","        self.img_rows = 256 \n","        self.img_cols = 256\n","        self.channels = 1\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","\n","        optimizer = Adam(0.0002, 0.5)\n","\n","        # Build and compile the discriminator\n","        self.discriminator = self.build_discriminator()\n","        self.discriminator.compile(loss='binary_crossentropy', \n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build and compile the generator\n","        self.generator = self.build_generator()\n","        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","        # The generator takes noise as input and generated imgs\n","        z = Input(shape=(400,))\n","        img = self.generator(z)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The valid takes generated images as input and determines validity\n","        valid = self.discriminator(img)\n","\n","        # The combined model  (stacked generator and discriminator) takes\n","        # noise as input => generates images => determines validity \n","        self.combined = Model(z, valid)\n","        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n","\n","    def build_generator(self):\n","\n","        noise_shape = (400,)\n","        \n","        model = Sequential()\n","\n","        model.add(Dense(1024, input_shape=noise_shape))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(2048))\n","        model.add(LeakyReLU(alpha=0.2))\n","        \n","        model.add(Dense(8192, input_shape=noise_shape))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(16384))\n","        model.add(LeakyReLU(alpha=0.2))\n","        \n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(32768))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(65536))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n","        model.add(Reshape(self.img_shape))\n","\n","        model.summary()\n","\n","        noise = Input(shape=noise_shape)\n","        img = model(noise)\n","\n","        return Model(noise, img)\n","\n","    def build_discriminator(self):\n","\n","        img_shape = (self.img_rows, self.img_cols, self.channels)\n","        \n","        model = Sequential()\n","\n","        model.add(Flatten(input_shape=img_shape))\n","        model.add(Dense(50000))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(60000))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(30000))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(10000))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(4000))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(1500))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(500))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(256))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dense(1, activation='sigmoid'))\n","        model.summary()\n","\n","        img = Input(shape=img_shape)\n","        validity = model(img)\n","\n","        return Model(img, validity)\n","\n","    def train(self, epochs, batch_size=128, save_interval=50):\n","\n","        # Load the dataset\n","        # (X_train, _), (_, _) = mnist.load_data()\n","        X_train = np.load(\"drive/Colab Notebooks/Data/ChestX_8/image_array_batch_0.npy\")\n","        \n","        # Rescale -1 to 1\n","        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","        X_train = np.expand_dims(X_train, axis=3)\n","\n","        half_batch = int(batch_size / 2)\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random half batch of images\n","            idx = np.random.randint(0, X_train.shape[0], half_batch)\n","            imgs = X_train[idx]\n","\n","            noise = np.random.normal(0, 1, (half_batch, 400))\n","\n","            # Generate a half batch of new images\n","            gen_imgs = self.generator.predict(noise)\n","\n","            # Train the discriminator\n","            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","\n","            # ---------------------\n","            #  Train Generator\n","            # ---------------------\n","\n","            noise = np.random.normal(0, 1, (batch_size, 400))\n","\n","            # The generator wants the discriminator to label the generated samples\n","            # as valid (ones)\n","            valid_y = np.array([1] * batch_size)\n","\n","            # Train the generator\n","            g_loss = self.combined.train_on_batch(noise, valid_y)\n","\n","            # Plot the progress\n","            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n","\n","            # If at save interval => save generated image samples\n","            if epoch % save_interval == 0:\n","                self.save_imgs(epoch)\n","\n","    def save_imgs(self, epoch):\n","        r, c = 5, 5\n","        noise = np.random.normal(0, 1, (r * c, 400))\n","        print(\"shape of noise: \"+ str(noise.shape))\n","        gen_imgs = self.generator.predict(noise)\n","\n","        # Rescale images 0 - 1\n","        gen_imgs = 0.5 * gen_imgs + 0.5\n","\n","        fig, axs = plt.subplots(r, c)\n","        cnt = 0\n","        for i in range(r):\n","            for j in range(c):\n","                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n","                axs[i,j].axis('off')\n","                cnt += 1\n","        fig.savefig(\"drive/Colab Notebooks/GAN Medical Image/Images Gen/Images GAN FirApt/mnist_%d.png\" % epoch)\n","        plt.close()\n","\n","\n","if __name__ == '__main__':\n","    gan = GAN()\n","    gan.train(epochs=30000, batch_size=32, save_interval=200)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","flatten_5 (Flatten)          (None, 65536)             0         \n","_________________________________________________________________\n","dense_65 (Dense)             (None, 50000)             3276850000\n","_________________________________________________________________\n","leaky_re_lu_57 (LeakyReLU)   (None, 50000)             0         \n","_________________________________________________________________\n","dense_66 (Dense)             (None, 60000)             3000060000\n","_________________________________________________________________\n","leaky_re_lu_58 (LeakyReLU)   (None, 60000)             0         \n","_________________________________________________________________\n","dense_67 (Dense)             (None, 30000)             1800030000\n","_________________________________________________________________\n","leaky_re_lu_59 (LeakyReLU)   (None, 30000)             0         \n","_________________________________________________________________\n","dense_68 (Dense)             (None, 10000)             300010000 \n","_________________________________________________________________\n","leaky_re_lu_60 (LeakyReLU)   (None, 10000)             0         \n","_________________________________________________________________\n","dense_69 (Dense)             (None, 4000)              40004000  \n","_________________________________________________________________\n","leaky_re_lu_61 (LeakyReLU)   (None, 4000)              0         \n","_________________________________________________________________\n","dense_70 (Dense)             (None, 1500)              6001500   \n","_________________________________________________________________\n","leaky_re_lu_62 (LeakyReLU)   (None, 1500)              0         \n","_________________________________________________________________\n","dense_71 (Dense)             (None, 500)               750500    \n","_________________________________________________________________\n","leaky_re_lu_63 (LeakyReLU)   (None, 500)               0         \n","_________________________________________________________________\n","dense_72 (Dense)             (None, 256)               128256    \n","_________________________________________________________________\n","leaky_re_lu_64 (LeakyReLU)   (None, 256)               0         \n","_________________________________________________________________\n","dense_73 (Dense)             (None, 1)                 257       \n","=================================================================\n","Total params: 8,423,834,513\n","Trainable params: 8,423,834,513\n","Non-trainable params: 0\n","_________________________________________________________________\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_74 (Dense)             (None, 1024)              410624    \n","_________________________________________________________________\n","leaky_re_lu_65 (LeakyReLU)   (None, 1024)              0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 1024)              4096      \n","_________________________________________________________________\n","dense_75 (Dense)             (None, 2048)              2099200   \n","_________________________________________________________________\n","leaky_re_lu_66 (LeakyReLU)   (None, 2048)              0         \n","_________________________________________________________________\n","dense_76 (Dense)             (None, 8192)              16785408  \n","_________________________________________________________________\n","leaky_re_lu_67 (LeakyReLU)   (None, 8192)              0         \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 8192)              32768     \n","_________________________________________________________________\n","dense_77 (Dense)             (None, 16384)             134234112 \n","_________________________________________________________________\n","leaky_re_lu_68 (LeakyReLU)   (None, 16384)             0         \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 16384)             65536     \n","_________________________________________________________________\n","dense_78 (Dense)             (None, 32768)             536903680 \n","_________________________________________________________________\n","leaky_re_lu_69 (LeakyReLU)   (None, 32768)             0         \n","_________________________________________________________________\n","dense_79 (Dense)             (None, 65536)             2147549184\n","_________________________________________________________________\n","leaky_re_lu_70 (LeakyReLU)   (None, 65536)             0         \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 65536)             262144    \n","_________________________________________________________________\n","dense_80 (Dense)             (None, 65536)             4295032832\n","_________________________________________________________________\n","reshape_5 (Reshape)          (None, 256, 256, 1)       0         \n","=================================================================\n","Total params: 7,133,379,584\n","Trainable params: 7,133,197,312\n","Non-trainable params: 182,272\n","_________________________________________________________________\n"],"name":"stdout"}]},{"metadata":{"id":"eBFotwQyohwW","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":5}],"base_uri":"https://localhost:8080/","height":138},"outputId":"7abd73da-1c21-475c-8a2a-72c74d62cd50","executionInfo":{"status":"ok","timestamp":1521477769267,"user_tz":-480,"elapsed":20730,"user":{"displayName":"也淇白","photoUrl":"//lh5.googleusercontent.com/-BKSlzGVuH74/AAAAAAAAAAI/AAAAAAAAAA4/ohUp2uylJAI/s50-c-k-no/photo.jpg","userId":"115711400106378591809"}}},"cell_type":"code","source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":1,"outputs":[{"output_type":"stream","text":["gpg: keybox '/tmp/tmpk7_wxet8/pubring.gpg' created\n","gpg: /tmp/tmpk7_wxet8/trustdb.gpg: trustdb created\n","gpg: key AD5F235DF639B041: public key \"Launchpad PPA for Alessandro Strada\" imported\n","gpg: Total number processed: 1\n","gpg:               imported: 1\n","Warning: apt-key output should not be parsed (stdout is not a terminal)\n","··········\n"],"name":"stdout"}]},{"metadata":{"id":"Xwn09roWoh8e","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":52},"outputId":"dd8e7319-7f53-4f3f-86c2-a1bfaf7ecfb9","executionInfo":{"status":"ok","timestamp":1521477774012,"user_tz":-480,"elapsed":3886,"user":{"displayName":"也淇白","photoUrl":"//lh5.googleusercontent.com/-BKSlzGVuH74/AAAAAAAAAAI/AAAAAAAAAA4/ohUp2uylJAI/s50-c-k-no/photo.jpg","userId":"115711400106378591809"}}},"cell_type":"code","source":["!mkdir -p drive\n","!google-drive-ocamlfuse drive\n","!pip install -q keras"],"execution_count":2,"outputs":[{"output_type":"stream","text":["fuse: mountpoint is not empty\r\n","fuse: if you are sure this is safe, use the 'nonempty' mount option\r\n"],"name":"stdout"}]},{"metadata":{"id":"Lc7KIyH5oiNG","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1}],"base_uri":"https://localhost:8080/","height":242},"outputId":"b7ef1ab9-13e0-4958-92f8-bc4a86d7e17e","executionInfo":{"status":"ok","timestamp":1521477787319,"user_tz":-480,"elapsed":1568,"user":{"displayName":"也淇白","photoUrl":"//lh5.googleusercontent.com/-BKSlzGVuH74/AAAAAAAAAAI/AAAAAAAAAA4/ohUp2uylJAI/s50-c-k-no/photo.jpg","userId":"115711400106378591809"}}},"cell_type":"code","source":["from tensorflow.python.client import device_lib\n","device_lib.list_local_devices()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 15753806634804022291, name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 255459328\n"," locality {\n","   bus_id: 1\n"," }\n"," incarnation: 15519817836642351765\n"," physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"]},"metadata":{"tags":[]},"execution_count":3}]}]}