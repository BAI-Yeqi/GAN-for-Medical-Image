{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Convolutional Generative Adversarial Network\n",
    "\n",
    "> This project is referred from the Github repository: https://github.com/eriklindernoren/Keras-GAN/tree/master/dcgan\n",
    "\n",
    "> The oop programming style is changed into process-oriented programming in ease of jupyter notebook\n",
    "\n",
    "> Images saved in the folder \"images_ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the build_generator function, which will return the model (will check out the Model() function later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "\n",
    "    noise_shape = (100,)\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_shape=noise_shape))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8)) \n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(1, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    noise = Input(shape=noise_shape)\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the build_discriminator function, which will return the discriminator model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    img_shape = (img_rows, img_cols, channels)\n",
    "        \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define the function that saves images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        #fig.suptitle(\"DCGAN: Generated digits\", fontsize=12)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images_ipynb/mnist_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define the class DCGAN, with the initialization and training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 392,705\n",
      "Trainable params: 392,321\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,705\n",
      "Trainable params: 856,065\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_rows = 28 \n",
    "img_cols = 28\n",
    "channels = 1\n",
    "\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', \n",
    "optimizer=optimizer,\n",
    "metrics=['accuracy'])\n",
    "\n",
    "# Build and compile the generator\n",
    "generator = build_generator()\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# The generator takes noise as input and generated imgs\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The valid takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator) takes\n",
    "# noise as input => generates images => determines validity \n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. define train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Sample noise and generate a half batch of new images\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator (real classified as ones and generated as zeros)\n",
    "            d_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # Train the generator (wants discriminator to mistake images as real)\n",
    "            g_loss = combined.train_on_batch(noise, np.ones((batch_size, 1)))\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                save_imgs(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. create a instance for DCGAN, and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BA0001QI\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:953: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [D loss: 0.902407, acc.: 46.88%] [G loss: 0.439658]\n",
      "1 [D loss: 0.763924, acc.: 56.25%] [G loss: 0.535989]\n",
      "2 [D loss: 0.649352, acc.: 62.50%] [G loss: 0.606408]\n",
      "3 [D loss: 0.621563, acc.: 71.88%] [G loss: 0.959201]\n",
      "4 [D loss: 0.490786, acc.: 75.00%] [G loss: 1.102031]\n",
      "5 [D loss: 0.333417, acc.: 90.62%] [G loss: 1.270628]\n",
      "6 [D loss: 0.298292, acc.: 90.62%] [G loss: 1.335451]\n",
      "7 [D loss: 0.308854, acc.: 93.75%] [G loss: 1.370368]\n",
      "8 [D loss: 0.287669, acc.: 87.50%] [G loss: 1.531201]\n",
      "9 [D loss: 0.283906, acc.: 87.50%] [G loss: 1.261654]\n",
      "10 [D loss: 0.312841, acc.: 90.62%] [G loss: 1.593414]\n",
      "11 [D loss: 0.241797, acc.: 93.75%] [G loss: 2.004383]\n",
      "12 [D loss: 0.306475, acc.: 93.75%] [G loss: 1.692974]\n",
      "13 [D loss: 0.179122, acc.: 96.88%] [G loss: 1.737354]\n",
      "14 [D loss: 0.249898, acc.: 93.75%] [G loss: 1.662880]\n",
      "15 [D loss: 0.200475, acc.: 93.75%] [G loss: 2.026259]\n",
      "16 [D loss: 0.211869, acc.: 93.75%] [G loss: 2.296104]\n",
      "17 [D loss: 0.151197, acc.: 100.00%] [G loss: 2.584612]\n",
      "18 [D loss: 0.159406, acc.: 96.88%] [G loss: 2.389112]\n",
      "19 [D loss: 0.116066, acc.: 100.00%] [G loss: 2.720599]\n",
      "20 [D loss: 0.155179, acc.: 96.88%] [G loss: 2.703464]\n",
      "21 [D loss: 0.087508, acc.: 100.00%] [G loss: 2.722049]\n",
      "22 [D loss: 0.144263, acc.: 96.88%] [G loss: 2.756525]\n",
      "23 [D loss: 0.152327, acc.: 96.88%] [G loss: 2.990255]\n",
      "24 [D loss: 0.174864, acc.: 90.62%] [G loss: 2.810182]\n",
      "25 [D loss: 0.112401, acc.: 100.00%] [G loss: 3.199886]\n",
      "26 [D loss: 0.148163, acc.: 93.75%] [G loss: 3.091055]\n",
      "27 [D loss: 0.115824, acc.: 96.88%] [G loss: 2.757478]\n",
      "28 [D loss: 0.091453, acc.: 96.88%] [G loss: 2.741253]\n",
      "29 [D loss: 0.112926, acc.: 100.00%] [G loss: 2.958699]\n",
      "30 [D loss: 0.073412, acc.: 100.00%] [G loss: 3.487410]\n",
      "31 [D loss: 0.055215, acc.: 100.00%] [G loss: 3.629490]\n",
      "32 [D loss: 0.164215, acc.: 96.88%] [G loss: 3.121762]\n",
      "33 [D loss: 0.083151, acc.: 96.88%] [G loss: 3.121013]\n",
      "34 [D loss: 0.133374, acc.: 96.88%] [G loss: 2.994226]\n",
      "35 [D loss: 0.078055, acc.: 100.00%] [G loss: 3.522126]\n",
      "36 [D loss: 0.115414, acc.: 96.88%] [G loss: 3.286492]\n",
      "37 [D loss: 0.059540, acc.: 100.00%] [G loss: 3.455703]\n",
      "38 [D loss: 0.097347, acc.: 100.00%] [G loss: 3.812953]\n",
      "39 [D loss: 0.095014, acc.: 100.00%] [G loss: 3.709612]\n",
      "40 [D loss: 0.175659, acc.: 100.00%] [G loss: 3.224751]\n",
      "41 [D loss: 0.063007, acc.: 100.00%] [G loss: 3.542092]\n",
      "42 [D loss: 0.024771, acc.: 100.00%] [G loss: 3.411871]\n",
      "43 [D loss: 0.109931, acc.: 100.00%] [G loss: 3.501025]\n",
      "44 [D loss: 0.058121, acc.: 100.00%] [G loss: 3.154987]\n",
      "45 [D loss: 0.073868, acc.: 100.00%] [G loss: 3.582393]\n",
      "46 [D loss: 0.150513, acc.: 96.88%] [G loss: 3.422894]\n",
      "47 [D loss: 0.104365, acc.: 100.00%] [G loss: 3.528559]\n",
      "48 [D loss: 0.080399, acc.: 100.00%] [G loss: 3.649848]\n",
      "49 [D loss: 0.056009, acc.: 100.00%] [G loss: 3.388053]\n",
      "50 [D loss: 0.159188, acc.: 96.88%] [G loss: 3.053073]\n",
      "51 [D loss: 0.110018, acc.: 96.88%] [G loss: 3.421092]\n",
      "52 [D loss: 0.037668, acc.: 100.00%] [G loss: 3.080959]\n",
      "53 [D loss: 0.097975, acc.: 96.88%] [G loss: 2.550217]\n",
      "54 [D loss: 0.082800, acc.: 100.00%] [G loss: 2.681033]\n",
      "55 [D loss: 0.130731, acc.: 100.00%] [G loss: 2.317485]\n",
      "56 [D loss: 0.094019, acc.: 100.00%] [G loss: 3.713044]\n",
      "57 [D loss: 0.066622, acc.: 100.00%] [G loss: 3.042909]\n",
      "58 [D loss: 0.085010, acc.: 100.00%] [G loss: 3.776535]\n",
      "59 [D loss: 0.260055, acc.: 96.88%] [G loss: 3.265049]\n",
      "60 [D loss: 0.034073, acc.: 100.00%] [G loss: 3.553274]\n",
      "61 [D loss: 0.088168, acc.: 100.00%] [G loss: 3.497051]\n",
      "62 [D loss: 0.169214, acc.: 100.00%] [G loss: 5.043550]\n",
      "63 [D loss: 0.151185, acc.: 100.00%] [G loss: 3.141506]\n",
      "64 [D loss: 0.140333, acc.: 96.88%] [G loss: 4.202313]\n",
      "65 [D loss: 0.461932, acc.: 71.88%] [G loss: 2.387172]\n",
      "66 [D loss: 0.104845, acc.: 100.00%] [G loss: 3.002977]\n",
      "67 [D loss: 0.045536, acc.: 100.00%] [G loss: 3.636848]\n",
      "68 [D loss: 0.094505, acc.: 100.00%] [G loss: 3.942802]\n",
      "69 [D loss: 0.133618, acc.: 96.88%] [G loss: 3.430270]\n",
      "70 [D loss: 0.139507, acc.: 96.88%] [G loss: 4.679336]\n",
      "71 [D loss: 0.512087, acc.: 71.88%] [G loss: 2.252112]\n",
      "72 [D loss: 0.071892, acc.: 100.00%] [G loss: 2.886580]\n",
      "73 [D loss: 0.105765, acc.: 100.00%] [G loss: 3.825738]\n",
      "74 [D loss: 0.242415, acc.: 90.62%] [G loss: 2.834989]\n",
      "75 [D loss: 0.560033, acc.: 68.75%] [G loss: 2.998349]\n",
      "76 [D loss: 0.063962, acc.: 100.00%] [G loss: 3.928343]\n",
      "77 [D loss: 0.307502, acc.: 87.50%] [G loss: 2.896197]\n",
      "78 [D loss: 0.312753, acc.: 87.50%] [G loss: 3.588065]\n",
      "79 [D loss: 0.151979, acc.: 96.88%] [G loss: 4.265328]\n",
      "80 [D loss: 0.932994, acc.: 59.38%] [G loss: 4.505869]\n",
      "81 [D loss: 0.389675, acc.: 81.25%] [G loss: 2.642827]\n",
      "82 [D loss: 0.252782, acc.: 87.50%] [G loss: 2.311594]\n",
      "83 [D loss: 1.018746, acc.: 53.12%] [G loss: 4.624634]\n",
      "84 [D loss: 0.627295, acc.: 68.75%] [G loss: 2.859605]\n",
      "85 [D loss: 0.522760, acc.: 68.75%] [G loss: 3.527241]\n",
      "86 [D loss: 0.777171, acc.: 59.38%] [G loss: 1.943143]\n",
      "87 [D loss: 0.468964, acc.: 81.25%] [G loss: 2.576226]\n",
      "88 [D loss: 0.770861, acc.: 59.38%] [G loss: 3.333302]\n",
      "89 [D loss: 1.513814, acc.: 31.25%] [G loss: 2.519459]\n",
      "90 [D loss: 0.833012, acc.: 56.25%] [G loss: 3.308244]\n",
      "91 [D loss: 0.981602, acc.: 46.88%] [G loss: 1.935215]\n",
      "92 [D loss: 0.464460, acc.: 78.12%] [G loss: 1.839912]\n",
      "93 [D loss: 1.151350, acc.: 46.88%] [G loss: 3.067572]\n",
      "94 [D loss: 0.764636, acc.: 56.25%] [G loss: 2.564888]\n",
      "95 [D loss: 0.907879, acc.: 50.00%] [G loss: 2.013418]\n",
      "96 [D loss: 0.558988, acc.: 65.62%] [G loss: 1.273953]\n",
      "97 [D loss: 1.064551, acc.: 50.00%] [G loss: 2.256127]\n",
      "98 [D loss: 0.737348, acc.: 62.50%] [G loss: 1.746617]\n",
      "99 [D loss: 1.171386, acc.: 34.38%] [G loss: 0.961844]\n",
      "100 [D loss: 0.940742, acc.: 62.50%] [G loss: 2.153960]\n",
      "101 [D loss: 1.181080, acc.: 50.00%] [G loss: 1.425419]\n",
      "102 [D loss: 1.027598, acc.: 56.25%] [G loss: 1.310725]\n",
      "103 [D loss: 1.091189, acc.: 34.38%] [G loss: 1.112887]\n",
      "104 [D loss: 1.000164, acc.: 34.38%] [G loss: 1.428866]\n",
      "105 [D loss: 0.855847, acc.: 56.25%] [G loss: 1.740882]\n",
      "106 [D loss: 0.950196, acc.: 56.25%] [G loss: 2.036777]\n",
      "107 [D loss: 1.138959, acc.: 43.75%] [G loss: 1.399042]\n",
      "108 [D loss: 1.230447, acc.: 40.62%] [G loss: 1.624530]\n",
      "109 [D loss: 0.933256, acc.: 46.88%] [G loss: 2.000045]\n",
      "110 [D loss: 1.216079, acc.: 34.38%] [G loss: 1.666939]\n",
      "111 [D loss: 1.064775, acc.: 46.88%] [G loss: 1.959662]\n",
      "112 [D loss: 1.331184, acc.: 37.50%] [G loss: 1.570699]\n",
      "113 [D loss: 0.783035, acc.: 50.00%] [G loss: 1.289567]\n",
      "114 [D loss: 0.781389, acc.: 59.38%] [G loss: 1.605001]\n",
      "115 [D loss: 0.756391, acc.: 59.38%] [G loss: 1.663741]\n",
      "116 [D loss: 0.912868, acc.: 43.75%] [G loss: 1.332184]\n",
      "117 [D loss: 1.038397, acc.: 43.75%] [G loss: 1.191592]\n",
      "118 [D loss: 0.898665, acc.: 50.00%] [G loss: 2.198997]\n",
      "119 [D loss: 0.720437, acc.: 65.62%] [G loss: 1.796751]\n",
      "120 [D loss: 1.193027, acc.: 34.38%] [G loss: 1.493668]\n",
      "121 [D loss: 1.230786, acc.: 31.25%] [G loss: 1.744214]\n",
      "122 [D loss: 0.881396, acc.: 43.75%] [G loss: 1.828078]\n",
      "123 [D loss: 0.999058, acc.: 43.75%] [G loss: 1.978866]\n",
      "124 [D loss: 1.336498, acc.: 37.50%] [G loss: 1.329633]\n",
      "125 [D loss: 0.857687, acc.: 56.25%] [G loss: 1.374004]\n",
      "126 [D loss: 0.896947, acc.: 40.62%] [G loss: 1.169223]\n",
      "127 [D loss: 1.053205, acc.: 53.12%] [G loss: 1.445119]\n",
      "128 [D loss: 0.644806, acc.: 75.00%] [G loss: 2.198712]\n",
      "129 [D loss: 1.088623, acc.: 34.38%] [G loss: 1.316212]\n",
      "130 [D loss: 1.114426, acc.: 31.25%] [G loss: 1.327630]\n",
      "131 [D loss: 0.932888, acc.: 53.12%] [G loss: 1.525975]\n",
      "132 [D loss: 0.719155, acc.: 62.50%] [G loss: 1.571968]\n",
      "133 [D loss: 0.735232, acc.: 59.38%] [G loss: 1.480834]\n",
      "134 [D loss: 0.863816, acc.: 59.38%] [G loss: 1.010561]\n",
      "135 [D loss: 0.882785, acc.: 43.75%] [G loss: 1.221781]\n",
      "136 [D loss: 0.903487, acc.: 37.50%] [G loss: 1.601543]\n",
      "137 [D loss: 0.736203, acc.: 65.62%] [G loss: 1.760494]\n",
      "138 [D loss: 0.907853, acc.: 46.88%] [G loss: 0.849381]\n",
      "139 [D loss: 0.748236, acc.: 59.38%] [G loss: 1.046246]\n",
      "140 [D loss: 0.869621, acc.: 53.12%] [G loss: 1.763979]\n",
      "141 [D loss: 0.624492, acc.: 68.75%] [G loss: 1.767846]\n",
      "142 [D loss: 0.577295, acc.: 68.75%] [G loss: 1.831084]\n",
      "143 [D loss: 0.757060, acc.: 65.62%] [G loss: 1.334454]\n",
      "144 [D loss: 0.628798, acc.: 50.00%] [G loss: 1.543458]\n",
      "145 [D loss: 0.762018, acc.: 59.38%] [G loss: 1.355624]\n",
      "146 [D loss: 0.584748, acc.: 75.00%] [G loss: 1.217943]\n",
      "147 [D loss: 0.846972, acc.: 50.00%] [G loss: 1.218642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 [D loss: 0.692429, acc.: 56.25%] [G loss: 1.065437]\n",
      "149 [D loss: 0.829018, acc.: 53.12%] [G loss: 1.222631]\n",
      "150 [D loss: 0.998056, acc.: 34.38%] [G loss: 1.278294]\n",
      "151 [D loss: 1.220851, acc.: 25.00%] [G loss: 1.094982]\n",
      "152 [D loss: 0.653417, acc.: 62.50%] [G loss: 1.518093]\n",
      "153 [D loss: 0.725619, acc.: 65.62%] [G loss: 1.725309]\n",
      "154 [D loss: 0.833992, acc.: 56.25%] [G loss: 1.180690]\n",
      "155 [D loss: 0.659775, acc.: 68.75%] [G loss: 1.383858]\n",
      "156 [D loss: 0.635319, acc.: 68.75%] [G loss: 1.309589]\n",
      "157 [D loss: 0.774112, acc.: 53.12%] [G loss: 1.457096]\n",
      "158 [D loss: 0.885877, acc.: 43.75%] [G loss: 0.801243]\n",
      "159 [D loss: 0.683906, acc.: 62.50%] [G loss: 1.176333]\n",
      "160 [D loss: 1.079083, acc.: 46.88%] [G loss: 1.280458]\n",
      "161 [D loss: 0.908999, acc.: 50.00%] [G loss: 1.376446]\n",
      "162 [D loss: 1.032539, acc.: 46.88%] [G loss: 1.265134]\n",
      "163 [D loss: 0.797673, acc.: 50.00%] [G loss: 1.318629]\n",
      "164 [D loss: 0.749917, acc.: 56.25%] [G loss: 1.190955]\n",
      "165 [D loss: 0.786852, acc.: 65.62%] [G loss: 1.288705]\n",
      "166 [D loss: 0.787922, acc.: 56.25%] [G loss: 1.499823]\n",
      "167 [D loss: 0.574433, acc.: 71.88%] [G loss: 1.136206]\n",
      "168 [D loss: 0.866377, acc.: 56.25%] [G loss: 1.550554]\n",
      "169 [D loss: 1.002801, acc.: 50.00%] [G loss: 1.616527]\n",
      "170 [D loss: 1.035358, acc.: 34.38%] [G loss: 1.587763]\n",
      "171 [D loss: 0.999759, acc.: 46.88%] [G loss: 1.273189]\n",
      "172 [D loss: 0.784580, acc.: 62.50%] [G loss: 1.065389]\n",
      "173 [D loss: 0.721362, acc.: 56.25%] [G loss: 1.597608]\n",
      "174 [D loss: 0.812630, acc.: 62.50%] [G loss: 1.392014]\n",
      "175 [D loss: 0.682303, acc.: 65.62%] [G loss: 1.322790]\n",
      "176 [D loss: 0.858327, acc.: 56.25%] [G loss: 1.024547]\n",
      "177 [D loss: 0.874960, acc.: 46.88%] [G loss: 1.075138]\n",
      "178 [D loss: 0.699962, acc.: 56.25%] [G loss: 1.119800]\n",
      "179 [D loss: 0.773066, acc.: 46.88%] [G loss: 0.955059]\n",
      "180 [D loss: 0.765018, acc.: 56.25%] [G loss: 1.418578]\n",
      "181 [D loss: 0.798081, acc.: 56.25%] [G loss: 1.206622]\n",
      "182 [D loss: 0.710433, acc.: 59.38%] [G loss: 1.145634]\n",
      "183 [D loss: 0.666982, acc.: 59.38%] [G loss: 1.133437]\n",
      "184 [D loss: 0.693569, acc.: 56.25%] [G loss: 1.724399]\n",
      "185 [D loss: 0.936401, acc.: 43.75%] [G loss: 1.521744]\n",
      "186 [D loss: 0.695890, acc.: 62.50%] [G loss: 1.345366]\n",
      "187 [D loss: 0.745887, acc.: 59.38%] [G loss: 1.355703]\n",
      "188 [D loss: 0.639061, acc.: 50.00%] [G loss: 1.395839]\n",
      "189 [D loss: 0.711715, acc.: 68.75%] [G loss: 1.292699]\n",
      "190 [D loss: 0.771118, acc.: 62.50%] [G loss: 1.205379]\n",
      "191 [D loss: 0.688756, acc.: 56.25%] [G loss: 1.333574]\n",
      "192 [D loss: 0.642219, acc.: 65.62%] [G loss: 1.078244]\n",
      "193 [D loss: 0.806879, acc.: 62.50%] [G loss: 1.733882]\n",
      "194 [D loss: 0.526686, acc.: 65.62%] [G loss: 1.655673]\n",
      "195 [D loss: 0.700167, acc.: 59.38%] [G loss: 0.982682]\n",
      "196 [D loss: 0.697700, acc.: 59.38%] [G loss: 1.524193]\n",
      "197 [D loss: 0.585426, acc.: 68.75%] [G loss: 1.496584]\n",
      "198 [D loss: 0.861052, acc.: 53.12%] [G loss: 1.271469]\n",
      "199 [D loss: 0.642179, acc.: 68.75%] [G loss: 1.314164]\n",
      "200 [D loss: 0.737996, acc.: 56.25%] [G loss: 1.334932]\n",
      "201 [D loss: 0.877003, acc.: 43.75%] [G loss: 1.268280]\n",
      "202 [D loss: 0.901074, acc.: 53.12%] [G loss: 1.439293]\n",
      "203 [D loss: 1.116569, acc.: 46.88%] [G loss: 1.177922]\n",
      "204 [D loss: 0.900098, acc.: 43.75%] [G loss: 1.313221]\n",
      "205 [D loss: 0.635128, acc.: 65.62%] [G loss: 1.451841]\n",
      "206 [D loss: 0.598566, acc.: 68.75%] [G loss: 1.183883]\n",
      "207 [D loss: 0.875742, acc.: 50.00%] [G loss: 1.027820]\n",
      "208 [D loss: 0.694251, acc.: 65.62%] [G loss: 1.237515]\n",
      "209 [D loss: 0.623944, acc.: 62.50%] [G loss: 1.416914]\n",
      "210 [D loss: 0.880619, acc.: 46.88%] [G loss: 1.100395]\n",
      "211 [D loss: 0.931678, acc.: 43.75%] [G loss: 1.139674]\n",
      "212 [D loss: 0.859414, acc.: 46.88%] [G loss: 1.263265]\n",
      "213 [D loss: 0.770603, acc.: 56.25%] [G loss: 1.340076]\n",
      "214 [D loss: 0.841803, acc.: 40.62%] [G loss: 1.279882]\n",
      "215 [D loss: 0.764330, acc.: 53.12%] [G loss: 1.233681]\n",
      "216 [D loss: 0.612691, acc.: 68.75%] [G loss: 1.254172]\n",
      "217 [D loss: 1.088431, acc.: 40.62%] [G loss: 1.096637]\n",
      "218 [D loss: 0.635614, acc.: 62.50%] [G loss: 1.115436]\n",
      "219 [D loss: 0.889402, acc.: 43.75%] [G loss: 1.300722]\n",
      "220 [D loss: 0.809654, acc.: 53.12%] [G loss: 1.003230]\n",
      "221 [D loss: 0.894472, acc.: 46.88%] [G loss: 0.872766]\n",
      "222 [D loss: 0.804723, acc.: 50.00%] [G loss: 1.159621]\n",
      "223 [D loss: 0.753880, acc.: 62.50%] [G loss: 1.467406]\n",
      "224 [D loss: 0.884279, acc.: 43.75%] [G loss: 1.405069]\n",
      "225 [D loss: 0.944496, acc.: 34.38%] [G loss: 1.273137]\n",
      "226 [D loss: 0.583973, acc.: 71.88%] [G loss: 1.424790]\n",
      "227 [D loss: 0.582586, acc.: 71.88%] [G loss: 1.566344]\n",
      "228 [D loss: 0.771790, acc.: 53.12%] [G loss: 1.437443]\n",
      "229 [D loss: 0.819122, acc.: 46.88%] [G loss: 1.187836]\n",
      "230 [D loss: 0.832377, acc.: 53.12%] [G loss: 1.220437]\n",
      "231 [D loss: 0.749699, acc.: 56.25%] [G loss: 1.128929]\n",
      "232 [D loss: 0.752620, acc.: 46.88%] [G loss: 1.245991]\n",
      "233 [D loss: 0.875773, acc.: 53.12%] [G loss: 1.320765]\n",
      "234 [D loss: 0.642191, acc.: 59.38%] [G loss: 1.183577]\n",
      "235 [D loss: 0.853606, acc.: 53.12%] [G loss: 1.330184]\n",
      "236 [D loss: 0.574356, acc.: 65.62%] [G loss: 1.282195]\n",
      "237 [D loss: 0.957231, acc.: 37.50%] [G loss: 1.149334]\n",
      "238 [D loss: 0.729155, acc.: 65.62%] [G loss: 1.390941]\n",
      "239 [D loss: 0.964630, acc.: 50.00%] [G loss: 1.088590]\n",
      "240 [D loss: 0.828348, acc.: 34.38%] [G loss: 1.171040]\n",
      "241 [D loss: 0.771137, acc.: 50.00%] [G loss: 1.204941]\n",
      "242 [D loss: 0.752076, acc.: 62.50%] [G loss: 1.147052]\n",
      "243 [D loss: 0.627727, acc.: 68.75%] [G loss: 1.014936]\n",
      "244 [D loss: 0.872845, acc.: 40.62%] [G loss: 0.979706]\n",
      "245 [D loss: 0.643299, acc.: 59.38%] [G loss: 1.485280]\n",
      "246 [D loss: 1.028666, acc.: 31.25%] [G loss: 1.309563]\n",
      "247 [D loss: 0.790910, acc.: 56.25%] [G loss: 1.081168]\n",
      "248 [D loss: 0.868259, acc.: 46.88%] [G loss: 1.495601]\n",
      "249 [D loss: 0.720356, acc.: 56.25%] [G loss: 1.215338]\n",
      "250 [D loss: 0.604644, acc.: 68.75%] [G loss: 1.127121]\n",
      "251 [D loss: 0.783452, acc.: 46.88%] [G loss: 1.057842]\n",
      "252 [D loss: 0.661329, acc.: 56.25%] [G loss: 1.502698]\n",
      "253 [D loss: 0.893060, acc.: 46.88%] [G loss: 1.314363]\n",
      "254 [D loss: 0.800356, acc.: 59.38%] [G loss: 1.335099]\n",
      "255 [D loss: 0.797519, acc.: 53.12%] [G loss: 1.232089]\n",
      "256 [D loss: 0.834404, acc.: 56.25%] [G loss: 1.366249]\n",
      "257 [D loss: 0.899924, acc.: 46.88%] [G loss: 1.089718]\n",
      "258 [D loss: 0.630406, acc.: 71.88%] [G loss: 1.296446]\n",
      "259 [D loss: 0.697079, acc.: 68.75%] [G loss: 1.156822]\n",
      "260 [D loss: 0.962887, acc.: 37.50%] [G loss: 0.906402]\n",
      "261 [D loss: 0.510773, acc.: 71.88%] [G loss: 1.281277]\n",
      "262 [D loss: 0.799772, acc.: 50.00%] [G loss: 1.457269]\n",
      "263 [D loss: 0.759679, acc.: 56.25%] [G loss: 1.262978]\n",
      "264 [D loss: 0.891700, acc.: 46.88%] [G loss: 1.325881]\n",
      "265 [D loss: 1.041142, acc.: 34.38%] [G loss: 1.049435]\n",
      "266 [D loss: 0.575052, acc.: 71.88%] [G loss: 1.298270]\n",
      "267 [D loss: 0.817690, acc.: 53.12%] [G loss: 1.154438]\n",
      "268 [D loss: 0.859760, acc.: 40.62%] [G loss: 1.453888]\n",
      "269 [D loss: 0.847890, acc.: 43.75%] [G loss: 0.960872]\n",
      "270 [D loss: 0.660580, acc.: 56.25%] [G loss: 1.028425]\n",
      "271 [D loss: 0.740382, acc.: 53.12%] [G loss: 1.291245]\n",
      "272 [D loss: 0.604193, acc.: 68.75%] [G loss: 1.137267]\n",
      "273 [D loss: 0.778476, acc.: 56.25%] [G loss: 0.844309]\n",
      "274 [D loss: 0.895157, acc.: 40.62%] [G loss: 1.108479]\n",
      "275 [D loss: 0.708595, acc.: 62.50%] [G loss: 1.459399]\n",
      "276 [D loss: 0.876015, acc.: 43.75%] [G loss: 1.276428]\n",
      "277 [D loss: 0.709744, acc.: 56.25%] [G loss: 1.110885]\n",
      "278 [D loss: 0.852928, acc.: 50.00%] [G loss: 1.111501]\n",
      "279 [D loss: 0.624343, acc.: 68.75%] [G loss: 1.461459]\n",
      "280 [D loss: 0.663191, acc.: 62.50%] [G loss: 1.188580]\n",
      "281 [D loss: 0.888965, acc.: 56.25%] [G loss: 1.261905]\n",
      "282 [D loss: 0.878523, acc.: 53.12%] [G loss: 1.418777]\n",
      "283 [D loss: 0.680947, acc.: 50.00%] [G loss: 1.395029]\n",
      "284 [D loss: 0.861162, acc.: 50.00%] [G loss: 1.228881]\n",
      "285 [D loss: 0.717181, acc.: 53.12%] [G loss: 1.235325]\n",
      "286 [D loss: 0.867903, acc.: 34.38%] [G loss: 0.889902]\n",
      "287 [D loss: 0.740970, acc.: 56.25%] [G loss: 1.363763]\n",
      "288 [D loss: 1.232567, acc.: 37.50%] [G loss: 1.150135]\n",
      "289 [D loss: 0.830862, acc.: 46.88%] [G loss: 1.511166]\n",
      "290 [D loss: 0.753324, acc.: 56.25%] [G loss: 1.087491]\n",
      "291 [D loss: 0.474835, acc.: 75.00%] [G loss: 1.373108]\n",
      "292 [D loss: 0.817551, acc.: 56.25%] [G loss: 1.082179]\n",
      "293 [D loss: 0.665670, acc.: 68.75%] [G loss: 1.308250]\n",
      "294 [D loss: 0.673632, acc.: 65.62%] [G loss: 1.165585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295 [D loss: 0.840636, acc.: 56.25%] [G loss: 1.054120]\n",
      "296 [D loss: 0.887882, acc.: 46.88%] [G loss: 1.313788]\n",
      "297 [D loss: 0.627429, acc.: 68.75%] [G loss: 1.076161]\n",
      "298 [D loss: 0.699562, acc.: 59.38%] [G loss: 1.241869]\n",
      "299 [D loss: 0.719564, acc.: 62.50%] [G loss: 1.100719]\n",
      "300 [D loss: 0.770139, acc.: 50.00%] [G loss: 1.270743]\n",
      "301 [D loss: 0.775158, acc.: 62.50%] [G loss: 0.933501]\n",
      "302 [D loss: 0.900275, acc.: 53.12%] [G loss: 0.959650]\n",
      "303 [D loss: 0.796108, acc.: 53.12%] [G loss: 1.282616]\n",
      "304 [D loss: 0.545692, acc.: 78.12%] [G loss: 1.466231]\n",
      "305 [D loss: 1.036043, acc.: 31.25%] [G loss: 1.021581]\n",
      "306 [D loss: 1.005529, acc.: 37.50%] [G loss: 1.208927]\n",
      "307 [D loss: 0.876571, acc.: 43.75%] [G loss: 1.291313]\n",
      "308 [D loss: 0.686699, acc.: 53.12%] [G loss: 1.455046]\n",
      "309 [D loss: 0.740936, acc.: 46.88%] [G loss: 1.313221]\n",
      "310 [D loss: 0.781486, acc.: 53.12%] [G loss: 1.033411]\n",
      "311 [D loss: 0.817895, acc.: 59.38%] [G loss: 1.239223]\n",
      "312 [D loss: 0.707297, acc.: 68.75%] [G loss: 1.285281]\n",
      "313 [D loss: 0.775396, acc.: 59.38%] [G loss: 1.469891]\n",
      "314 [D loss: 0.861299, acc.: 40.62%] [G loss: 0.976558]\n",
      "315 [D loss: 0.740358, acc.: 56.25%] [G loss: 1.104969]\n",
      "316 [D loss: 0.634091, acc.: 62.50%] [G loss: 1.278600]\n",
      "317 [D loss: 0.750999, acc.: 53.12%] [G loss: 0.886700]\n",
      "318 [D loss: 0.855787, acc.: 43.75%] [G loss: 1.137604]\n",
      "319 [D loss: 0.692306, acc.: 65.62%] [G loss: 1.413960]\n",
      "320 [D loss: 1.025405, acc.: 40.62%] [G loss: 1.005922]\n",
      "321 [D loss: 0.751127, acc.: 53.12%] [G loss: 1.291532]\n",
      "322 [D loss: 0.755046, acc.: 56.25%] [G loss: 1.362126]\n",
      "323 [D loss: 0.980039, acc.: 34.38%] [G loss: 0.967120]\n",
      "324 [D loss: 0.727893, acc.: 50.00%] [G loss: 1.098303]\n",
      "325 [D loss: 0.805128, acc.: 40.62%] [G loss: 1.283745]\n",
      "326 [D loss: 0.752895, acc.: 56.25%] [G loss: 1.132970]\n",
      "327 [D loss: 0.664585, acc.: 68.75%] [G loss: 0.986373]\n",
      "328 [D loss: 0.890538, acc.: 46.88%] [G loss: 1.111566]\n",
      "329 [D loss: 0.633712, acc.: 75.00%] [G loss: 1.187663]\n",
      "330 [D loss: 0.847599, acc.: 46.88%] [G loss: 1.367338]\n",
      "331 [D loss: 0.666047, acc.: 59.38%] [G loss: 1.263243]\n",
      "332 [D loss: 0.710483, acc.: 65.62%] [G loss: 1.308827]\n",
      "333 [D loss: 0.754207, acc.: 56.25%] [G loss: 1.081432]\n",
      "334 [D loss: 0.732772, acc.: 56.25%] [G loss: 1.045287]\n",
      "335 [D loss: 0.908347, acc.: 46.88%] [G loss: 1.162556]\n",
      "336 [D loss: 0.769438, acc.: 53.12%] [G loss: 1.208048]\n",
      "337 [D loss: 0.551815, acc.: 65.62%] [G loss: 1.172783]\n",
      "338 [D loss: 0.860238, acc.: 40.62%] [G loss: 1.172235]\n",
      "339 [D loss: 0.779582, acc.: 50.00%] [G loss: 1.415239]\n",
      "340 [D loss: 0.738159, acc.: 59.38%] [G loss: 1.148792]\n",
      "341 [D loss: 0.589762, acc.: 59.38%] [G loss: 0.958528]\n",
      "342 [D loss: 0.750111, acc.: 53.12%] [G loss: 1.170238]\n",
      "343 [D loss: 0.746444, acc.: 50.00%] [G loss: 1.134818]\n",
      "344 [D loss: 0.575234, acc.: 75.00%] [G loss: 1.238617]\n",
      "345 [D loss: 0.747068, acc.: 59.38%] [G loss: 1.247570]\n",
      "346 [D loss: 0.586458, acc.: 65.62%] [G loss: 1.151001]\n",
      "347 [D loss: 0.688939, acc.: 59.38%] [G loss: 1.340059]\n",
      "348 [D loss: 0.793744, acc.: 53.12%] [G loss: 1.140113]\n",
      "349 [D loss: 0.972483, acc.: 46.88%] [G loss: 1.235675]\n",
      "350 [D loss: 0.708467, acc.: 59.38%] [G loss: 1.060387]\n",
      "351 [D loss: 0.859270, acc.: 50.00%] [G loss: 0.934100]\n",
      "352 [D loss: 0.735997, acc.: 62.50%] [G loss: 0.856491]\n",
      "353 [D loss: 0.772257, acc.: 62.50%] [G loss: 1.307232]\n",
      "354 [D loss: 0.706786, acc.: 56.25%] [G loss: 1.270435]\n",
      "355 [D loss: 0.698770, acc.: 62.50%] [G loss: 1.201674]\n",
      "356 [D loss: 0.575146, acc.: 71.88%] [G loss: 1.064947]\n",
      "357 [D loss: 0.718742, acc.: 59.38%] [G loss: 1.373530]\n",
      "358 [D loss: 0.786927, acc.: 50.00%] [G loss: 1.402801]\n",
      "359 [D loss: 0.681357, acc.: 62.50%] [G loss: 1.416831]\n",
      "360 [D loss: 0.894181, acc.: 56.25%] [G loss: 1.214482]\n",
      "361 [D loss: 0.622170, acc.: 68.75%] [G loss: 1.511652]\n",
      "362 [D loss: 0.983964, acc.: 43.75%] [G loss: 0.774824]\n",
      "363 [D loss: 0.729244, acc.: 59.38%] [G loss: 1.253744]\n",
      "364 [D loss: 0.734053, acc.: 59.38%] [G loss: 1.123924]\n",
      "365 [D loss: 0.676702, acc.: 53.12%] [G loss: 1.089665]\n",
      "366 [D loss: 0.634858, acc.: 59.38%] [G loss: 1.265805]\n",
      "367 [D loss: 0.952512, acc.: 28.12%] [G loss: 1.187195]\n",
      "368 [D loss: 0.778616, acc.: 53.12%] [G loss: 1.185408]\n",
      "369 [D loss: 0.868275, acc.: 50.00%] [G loss: 0.972591]\n",
      "370 [D loss: 0.644513, acc.: 65.62%] [G loss: 1.212785]\n",
      "371 [D loss: 0.708834, acc.: 59.38%] [G loss: 1.356445]\n",
      "372 [D loss: 0.693477, acc.: 62.50%] [G loss: 1.408357]\n",
      "373 [D loss: 0.813034, acc.: 56.25%] [G loss: 1.057205]\n",
      "374 [D loss: 0.778225, acc.: 56.25%] [G loss: 1.165190]\n",
      "375 [D loss: 1.023138, acc.: 37.50%] [G loss: 1.049538]\n",
      "376 [D loss: 0.787714, acc.: 50.00%] [G loss: 1.193719]\n",
      "377 [D loss: 0.883316, acc.: 43.75%] [G loss: 0.911849]\n",
      "378 [D loss: 1.032293, acc.: 31.25%] [G loss: 1.012090]\n",
      "379 [D loss: 0.730726, acc.: 59.38%] [G loss: 0.873984]\n",
      "380 [D loss: 0.767918, acc.: 53.12%] [G loss: 0.975909]\n",
      "381 [D loss: 0.747240, acc.: 56.25%] [G loss: 1.013052]\n",
      "382 [D loss: 0.914906, acc.: 37.50%] [G loss: 1.119713]\n",
      "383 [D loss: 0.563108, acc.: 75.00%] [G loss: 1.297720]\n",
      "384 [D loss: 0.677884, acc.: 62.50%] [G loss: 1.038170]\n",
      "385 [D loss: 0.841488, acc.: 50.00%] [G loss: 1.133034]\n",
      "386 [D loss: 0.832561, acc.: 53.12%] [G loss: 1.034276]\n",
      "387 [D loss: 0.807365, acc.: 50.00%] [G loss: 1.016128]\n",
      "388 [D loss: 0.659027, acc.: 59.38%] [G loss: 1.035513]\n",
      "389 [D loss: 0.672584, acc.: 62.50%] [G loss: 1.142545]\n",
      "390 [D loss: 0.720709, acc.: 53.12%] [G loss: 1.104450]\n",
      "391 [D loss: 0.665711, acc.: 59.38%] [G loss: 1.090783]\n",
      "392 [D loss: 0.809115, acc.: 50.00%] [G loss: 1.273149]\n",
      "393 [D loss: 0.635757, acc.: 59.38%] [G loss: 1.094711]\n",
      "394 [D loss: 0.894118, acc.: 43.75%] [G loss: 1.080051]\n",
      "395 [D loss: 0.784193, acc.: 46.88%] [G loss: 1.231107]\n",
      "396 [D loss: 0.641788, acc.: 59.38%] [G loss: 1.118937]\n",
      "397 [D loss: 0.601448, acc.: 71.88%] [G loss: 1.300003]\n",
      "398 [D loss: 0.663686, acc.: 62.50%] [G loss: 0.859023]\n",
      "399 [D loss: 0.695282, acc.: 62.50%] [G loss: 1.028115]\n",
      "400 [D loss: 0.686186, acc.: 65.62%] [G loss: 1.029349]\n",
      "401 [D loss: 0.785893, acc.: 50.00%] [G loss: 1.057612]\n",
      "402 [D loss: 0.834145, acc.: 50.00%] [G loss: 0.978913]\n",
      "403 [D loss: 0.725055, acc.: 62.50%] [G loss: 1.223158]\n",
      "404 [D loss: 0.684477, acc.: 62.50%] [G loss: 1.203078]\n",
      "405 [D loss: 0.718129, acc.: 56.25%] [G loss: 1.099075]\n",
      "406 [D loss: 0.830028, acc.: 43.75%] [G loss: 1.141748]\n",
      "407 [D loss: 0.824556, acc.: 46.88%] [G loss: 1.148054]\n",
      "408 [D loss: 0.721487, acc.: 50.00%] [G loss: 1.255932]\n",
      "409 [D loss: 0.800871, acc.: 50.00%] [G loss: 0.976779]\n",
      "410 [D loss: 0.812668, acc.: 46.88%] [G loss: 1.219675]\n",
      "411 [D loss: 0.747748, acc.: 62.50%] [G loss: 1.011677]\n",
      "412 [D loss: 0.903289, acc.: 34.38%] [G loss: 1.123925]\n",
      "413 [D loss: 0.742266, acc.: 62.50%] [G loss: 1.187044]\n",
      "414 [D loss: 0.743644, acc.: 62.50%] [G loss: 1.012964]\n",
      "415 [D loss: 0.832587, acc.: 43.75%] [G loss: 0.951684]\n",
      "416 [D loss: 0.905262, acc.: 28.12%] [G loss: 0.989998]\n",
      "417 [D loss: 0.755181, acc.: 53.12%] [G loss: 1.288272]\n",
      "418 [D loss: 0.681041, acc.: 62.50%] [G loss: 1.105869]\n",
      "419 [D loss: 0.780241, acc.: 40.62%] [G loss: 1.110385]\n",
      "420 [D loss: 1.043064, acc.: 28.12%] [G loss: 1.131605]\n",
      "421 [D loss: 0.595287, acc.: 65.62%] [G loss: 1.114692]\n",
      "422 [D loss: 0.748072, acc.: 43.75%] [G loss: 1.006992]\n",
      "423 [D loss: 0.598997, acc.: 65.62%] [G loss: 1.044488]\n",
      "424 [D loss: 0.588964, acc.: 59.38%] [G loss: 1.087428]\n",
      "425 [D loss: 0.753823, acc.: 56.25%] [G loss: 1.153103]\n",
      "426 [D loss: 0.682286, acc.: 53.12%] [G loss: 1.194216]\n",
      "427 [D loss: 0.692889, acc.: 71.88%] [G loss: 0.954890]\n",
      "428 [D loss: 0.739038, acc.: 56.25%] [G loss: 1.215596]\n",
      "429 [D loss: 0.817405, acc.: 43.75%] [G loss: 1.097538]\n",
      "430 [D loss: 0.886880, acc.: 37.50%] [G loss: 1.046337]\n",
      "431 [D loss: 0.774604, acc.: 43.75%] [G loss: 1.155303]\n",
      "432 [D loss: 0.796167, acc.: 53.12%] [G loss: 1.208909]\n",
      "433 [D loss: 0.819652, acc.: 46.88%] [G loss: 1.076174]\n",
      "434 [D loss: 0.760758, acc.: 43.75%] [G loss: 1.101558]\n",
      "435 [D loss: 0.644520, acc.: 59.38%] [G loss: 1.051008]\n",
      "436 [D loss: 0.670868, acc.: 53.12%] [G loss: 1.107328]\n",
      "437 [D loss: 0.805195, acc.: 56.25%] [G loss: 1.278142]\n",
      "438 [D loss: 0.793339, acc.: 53.12%] [G loss: 1.351675]\n",
      "439 [D loss: 0.856568, acc.: 40.62%] [G loss: 1.117047]\n",
      "440 [D loss: 0.594247, acc.: 65.62%] [G loss: 1.248984]\n",
      "441 [D loss: 0.833109, acc.: 50.00%] [G loss: 1.073168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442 [D loss: 0.970323, acc.: 40.62%] [G loss: 1.088381]\n",
      "443 [D loss: 0.637695, acc.: 68.75%] [G loss: 0.906712]\n",
      "444 [D loss: 0.813604, acc.: 46.88%] [G loss: 1.083074]\n",
      "445 [D loss: 0.781277, acc.: 43.75%] [G loss: 1.119287]\n",
      "446 [D loss: 0.798252, acc.: 53.12%] [G loss: 1.156396]\n",
      "447 [D loss: 0.725546, acc.: 50.00%] [G loss: 0.835162]\n",
      "448 [D loss: 0.865333, acc.: 53.12%] [G loss: 0.891121]\n",
      "449 [D loss: 1.004199, acc.: 28.12%] [G loss: 0.977537]\n",
      "450 [D loss: 0.573659, acc.: 62.50%] [G loss: 1.625674]\n",
      "451 [D loss: 0.752980, acc.: 59.38%] [G loss: 1.349520]\n",
      "452 [D loss: 0.745969, acc.: 53.12%] [G loss: 1.069369]\n",
      "453 [D loss: 0.676413, acc.: 56.25%] [G loss: 1.048650]\n",
      "454 [D loss: 0.732593, acc.: 56.25%] [G loss: 0.957101]\n",
      "455 [D loss: 0.831805, acc.: 46.88%] [G loss: 1.099005]\n",
      "456 [D loss: 0.727723, acc.: 53.12%] [G loss: 0.959381]\n",
      "457 [D loss: 0.740233, acc.: 46.88%] [G loss: 0.941880]\n",
      "458 [D loss: 0.731180, acc.: 59.38%] [G loss: 0.880248]\n",
      "459 [D loss: 0.860542, acc.: 43.75%] [G loss: 1.050767]\n",
      "460 [D loss: 0.784934, acc.: 56.25%] [G loss: 1.102835]\n",
      "461 [D loss: 0.788796, acc.: 37.50%] [G loss: 1.089865]\n",
      "462 [D loss: 0.755913, acc.: 50.00%] [G loss: 1.035094]\n",
      "463 [D loss: 0.826934, acc.: 40.62%] [G loss: 1.024029]\n",
      "464 [D loss: 0.729095, acc.: 50.00%] [G loss: 0.906442]\n",
      "465 [D loss: 0.719676, acc.: 59.38%] [G loss: 1.185464]\n",
      "466 [D loss: 0.761929, acc.: 50.00%] [G loss: 1.161426]\n",
      "467 [D loss: 0.775188, acc.: 50.00%] [G loss: 1.065742]\n",
      "468 [D loss: 0.745231, acc.: 53.12%] [G loss: 1.477834]\n",
      "469 [D loss: 0.754794, acc.: 46.88%] [G loss: 1.142187]\n",
      "470 [D loss: 0.819930, acc.: 43.75%] [G loss: 0.981411]\n",
      "471 [D loss: 0.612835, acc.: 65.62%] [G loss: 1.119471]\n",
      "472 [D loss: 0.914873, acc.: 40.62%] [G loss: 0.949853]\n",
      "473 [D loss: 0.733532, acc.: 53.12%] [G loss: 1.035560]\n",
      "474 [D loss: 0.950705, acc.: 34.38%] [G loss: 1.362930]\n",
      "475 [D loss: 0.822445, acc.: 50.00%] [G loss: 0.944644]\n",
      "476 [D loss: 0.757515, acc.: 62.50%] [G loss: 1.129278]\n",
      "477 [D loss: 0.805681, acc.: 43.75%] [G loss: 1.117477]\n",
      "478 [D loss: 0.738241, acc.: 56.25%] [G loss: 1.113569]\n",
      "479 [D loss: 0.877372, acc.: 46.88%] [G loss: 1.225493]\n",
      "480 [D loss: 0.896545, acc.: 50.00%] [G loss: 1.193787]\n",
      "481 [D loss: 0.667572, acc.: 53.12%] [G loss: 1.167381]\n",
      "482 [D loss: 0.696210, acc.: 56.25%] [G loss: 1.183720]\n",
      "483 [D loss: 0.842039, acc.: 43.75%] [G loss: 0.865328]\n",
      "484 [D loss: 0.722910, acc.: 56.25%] [G loss: 1.222964]\n",
      "485 [D loss: 0.615117, acc.: 68.75%] [G loss: 0.905274]\n",
      "486 [D loss: 0.650492, acc.: 59.38%] [G loss: 0.951963]\n",
      "487 [D loss: 0.811716, acc.: 43.75%] [G loss: 0.921792]\n",
      "488 [D loss: 0.777925, acc.: 53.12%] [G loss: 1.071639]\n",
      "489 [D loss: 0.823748, acc.: 53.12%] [G loss: 1.064672]\n",
      "490 [D loss: 0.722925, acc.: 59.38%] [G loss: 1.336748]\n",
      "491 [D loss: 0.810824, acc.: 46.88%] [G loss: 0.937036]\n",
      "492 [D loss: 0.572047, acc.: 75.00%] [G loss: 1.078765]\n",
      "493 [D loss: 0.959084, acc.: 40.62%] [G loss: 1.017684]\n",
      "494 [D loss: 0.750052, acc.: 53.12%] [G loss: 1.156965]\n",
      "495 [D loss: 0.803673, acc.: 46.88%] [G loss: 0.880715]\n",
      "496 [D loss: 0.745564, acc.: 53.12%] [G loss: 1.242903]\n",
      "497 [D loss: 0.758892, acc.: 62.50%] [G loss: 0.846863]\n",
      "498 [D loss: 0.743148, acc.: 43.75%] [G loss: 1.102901]\n",
      "499 [D loss: 0.868600, acc.: 46.88%] [G loss: 0.955260]\n",
      "500 [D loss: 0.911189, acc.: 43.75%] [G loss: 1.022288]\n",
      "501 [D loss: 0.706506, acc.: 59.38%] [G loss: 1.046486]\n",
      "502 [D loss: 0.844427, acc.: 56.25%] [G loss: 1.198476]\n",
      "503 [D loss: 0.720875, acc.: 53.12%] [G loss: 1.026778]\n",
      "504 [D loss: 0.766023, acc.: 53.12%] [G loss: 0.932348]\n",
      "505 [D loss: 0.870755, acc.: 46.88%] [G loss: 1.172862]\n",
      "506 [D loss: 0.581354, acc.: 68.75%] [G loss: 1.041349]\n",
      "507 [D loss: 0.654768, acc.: 62.50%] [G loss: 1.071631]\n",
      "508 [D loss: 0.855513, acc.: 50.00%] [G loss: 1.011587]\n",
      "509 [D loss: 0.838250, acc.: 46.88%] [G loss: 1.106456]\n",
      "510 [D loss: 0.878076, acc.: 43.75%] [G loss: 1.048184]\n",
      "511 [D loss: 0.705594, acc.: 56.25%] [G loss: 1.091811]\n",
      "512 [D loss: 0.713881, acc.: 46.88%] [G loss: 1.045001]\n",
      "513 [D loss: 0.672594, acc.: 71.88%] [G loss: 1.157486]\n",
      "514 [D loss: 0.528272, acc.: 78.12%] [G loss: 1.258120]\n",
      "515 [D loss: 0.675752, acc.: 68.75%] [G loss: 1.180074]\n",
      "516 [D loss: 0.701674, acc.: 62.50%] [G loss: 0.939340]\n",
      "517 [D loss: 0.712196, acc.: 59.38%] [G loss: 0.913755]\n",
      "518 [D loss: 0.611955, acc.: 75.00%] [G loss: 1.223053]\n",
      "519 [D loss: 0.821107, acc.: 46.88%] [G loss: 0.984462]\n",
      "520 [D loss: 0.855629, acc.: 40.62%] [G loss: 1.022767]\n",
      "521 [D loss: 0.906830, acc.: 37.50%] [G loss: 1.011524]\n",
      "522 [D loss: 0.757482, acc.: 46.88%] [G loss: 0.964147]\n",
      "523 [D loss: 0.767364, acc.: 46.88%] [G loss: 1.238652]\n",
      "524 [D loss: 0.691568, acc.: 59.38%] [G loss: 0.981665]\n",
      "525 [D loss: 0.731781, acc.: 56.25%] [G loss: 1.282564]\n",
      "526 [D loss: 0.739524, acc.: 50.00%] [G loss: 1.054779]\n",
      "527 [D loss: 0.716459, acc.: 50.00%] [G loss: 1.133201]\n",
      "528 [D loss: 0.663085, acc.: 62.50%] [G loss: 1.027175]\n",
      "529 [D loss: 0.781619, acc.: 46.88%] [G loss: 1.002981]\n",
      "530 [D loss: 0.651477, acc.: 59.38%] [G loss: 0.921264]\n",
      "531 [D loss: 0.874467, acc.: 40.62%] [G loss: 1.081185]\n",
      "532 [D loss: 0.613689, acc.: 71.88%] [G loss: 1.097005]\n",
      "533 [D loss: 0.848166, acc.: 37.50%] [G loss: 0.918949]\n",
      "534 [D loss: 0.709253, acc.: 65.62%] [G loss: 1.023921]\n",
      "535 [D loss: 0.742587, acc.: 56.25%] [G loss: 1.092152]\n",
      "536 [D loss: 0.697440, acc.: 68.75%] [G loss: 0.875868]\n",
      "537 [D loss: 0.575610, acc.: 59.38%] [G loss: 0.831845]\n",
      "538 [D loss: 0.735888, acc.: 56.25%] [G loss: 0.804209]\n",
      "539 [D loss: 0.631274, acc.: 68.75%] [G loss: 1.032150]\n",
      "540 [D loss: 0.742775, acc.: 50.00%] [G loss: 1.149904]\n",
      "541 [D loss: 0.858907, acc.: 37.50%] [G loss: 0.807236]\n",
      "542 [D loss: 0.734172, acc.: 59.38%] [G loss: 1.114111]\n",
      "543 [D loss: 0.608027, acc.: 62.50%] [G loss: 1.014368]\n",
      "544 [D loss: 0.763895, acc.: 43.75%] [G loss: 1.108045]\n",
      "545 [D loss: 0.682494, acc.: 46.88%] [G loss: 0.970219]\n",
      "546 [D loss: 0.749859, acc.: 59.38%] [G loss: 0.930682]\n",
      "547 [D loss: 0.763361, acc.: 53.12%] [G loss: 1.058448]\n",
      "548 [D loss: 0.604262, acc.: 68.75%] [G loss: 1.078926]\n",
      "549 [D loss: 0.647104, acc.: 68.75%] [G loss: 1.034276]\n",
      "550 [D loss: 0.689214, acc.: 53.12%] [G loss: 1.281240]\n",
      "551 [D loss: 0.716718, acc.: 53.12%] [G loss: 1.318046]\n",
      "552 [D loss: 0.804515, acc.: 43.75%] [G loss: 1.156236]\n",
      "553 [D loss: 0.749517, acc.: 50.00%] [G loss: 0.976071]\n",
      "554 [D loss: 0.672876, acc.: 62.50%] [G loss: 1.099386]\n",
      "555 [D loss: 0.605241, acc.: 65.62%] [G loss: 1.250881]\n",
      "556 [D loss: 0.671765, acc.: 65.62%] [G loss: 0.956697]\n",
      "557 [D loss: 0.639251, acc.: 65.62%] [G loss: 0.960285]\n",
      "558 [D loss: 0.647928, acc.: 56.25%] [G loss: 0.975467]\n",
      "559 [D loss: 0.683705, acc.: 56.25%] [G loss: 0.885395]\n",
      "560 [D loss: 0.763800, acc.: 46.88%] [G loss: 0.936840]\n",
      "561 [D loss: 0.894552, acc.: 28.12%] [G loss: 0.926462]\n",
      "562 [D loss: 0.711726, acc.: 53.12%] [G loss: 1.010922]\n",
      "563 [D loss: 0.682765, acc.: 62.50%] [G loss: 0.959520]\n",
      "564 [D loss: 0.781684, acc.: 43.75%] [G loss: 1.023490]\n",
      "565 [D loss: 0.937515, acc.: 37.50%] [G loss: 1.136645]\n",
      "566 [D loss: 0.643115, acc.: 62.50%] [G loss: 1.063137]\n",
      "567 [D loss: 0.559830, acc.: 78.12%] [G loss: 1.155707]\n",
      "568 [D loss: 0.618054, acc.: 78.12%] [G loss: 0.828853]\n",
      "569 [D loss: 0.699099, acc.: 56.25%] [G loss: 1.017370]\n",
      "570 [D loss: 0.876495, acc.: 46.88%] [G loss: 1.008757]\n",
      "571 [D loss: 0.733266, acc.: 59.38%] [G loss: 0.978572]\n",
      "572 [D loss: 0.997678, acc.: 34.38%] [G loss: 0.887470]\n",
      "573 [D loss: 0.799204, acc.: 46.88%] [G loss: 0.869694]\n",
      "574 [D loss: 0.747674, acc.: 53.12%] [G loss: 0.914962]\n",
      "575 [D loss: 0.763816, acc.: 46.88%] [G loss: 1.038433]\n",
      "576 [D loss: 0.689258, acc.: 56.25%] [G loss: 1.038184]\n",
      "577 [D loss: 0.792599, acc.: 34.38%] [G loss: 1.086991]\n",
      "578 [D loss: 0.824841, acc.: 43.75%] [G loss: 1.138214]\n",
      "579 [D loss: 0.659782, acc.: 59.38%] [G loss: 1.059449]\n",
      "580 [D loss: 0.625887, acc.: 65.62%] [G loss: 1.024435]\n",
      "581 [D loss: 0.709096, acc.: 56.25%] [G loss: 0.952520]\n",
      "582 [D loss: 0.890294, acc.: 28.12%] [G loss: 1.075536]\n",
      "583 [D loss: 0.699837, acc.: 50.00%] [G loss: 1.087193]\n",
      "584 [D loss: 0.717030, acc.: 59.38%] [G loss: 1.025721]\n",
      "585 [D loss: 0.535066, acc.: 81.25%] [G loss: 1.117993]\n",
      "586 [D loss: 0.673984, acc.: 65.62%] [G loss: 0.946918]\n",
      "587 [D loss: 0.800793, acc.: 46.88%] [G loss: 1.066566]\n",
      "588 [D loss: 0.735727, acc.: 46.88%] [G loss: 0.964327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 [D loss: 0.905579, acc.: 31.25%] [G loss: 0.956647]\n",
      "590 [D loss: 0.616740, acc.: 62.50%] [G loss: 1.156603]\n",
      "591 [D loss: 0.659334, acc.: 53.12%] [G loss: 0.999609]\n",
      "592 [D loss: 0.714075, acc.: 46.88%] [G loss: 1.088974]\n",
      "593 [D loss: 0.665355, acc.: 59.38%] [G loss: 1.032866]\n",
      "594 [D loss: 0.485412, acc.: 81.25%] [G loss: 0.965558]\n",
      "595 [D loss: 0.779906, acc.: 53.12%] [G loss: 1.211773]\n",
      "596 [D loss: 0.737335, acc.: 50.00%] [G loss: 1.062141]\n",
      "597 [D loss: 0.705926, acc.: 65.62%] [G loss: 1.353651]\n",
      "598 [D loss: 0.607163, acc.: 59.38%] [G loss: 1.046435]\n",
      "599 [D loss: 0.783138, acc.: 50.00%] [G loss: 1.000127]\n",
      "600 [D loss: 0.828143, acc.: 40.62%] [G loss: 0.913746]\n",
      "601 [D loss: 0.830508, acc.: 50.00%] [G loss: 0.890668]\n",
      "602 [D loss: 0.509970, acc.: 75.00%] [G loss: 1.201080]\n",
      "603 [D loss: 0.732848, acc.: 43.75%] [G loss: 1.023168]\n",
      "604 [D loss: 0.737843, acc.: 53.12%] [G loss: 1.136494]\n",
      "605 [D loss: 0.735560, acc.: 50.00%] [G loss: 1.033116]\n",
      "606 [D loss: 0.605689, acc.: 68.75%] [G loss: 1.154539]\n",
      "607 [D loss: 0.669594, acc.: 62.50%] [G loss: 0.965002]\n",
      "608 [D loss: 0.598000, acc.: 68.75%] [G loss: 1.216858]\n",
      "609 [D loss: 0.724622, acc.: 56.25%] [G loss: 1.301750]\n",
      "610 [D loss: 0.553223, acc.: 81.25%] [G loss: 1.097727]\n",
      "611 [D loss: 0.744385, acc.: 46.88%] [G loss: 1.121464]\n",
      "612 [D loss: 0.921695, acc.: 40.62%] [G loss: 0.979767]\n",
      "613 [D loss: 0.667145, acc.: 62.50%] [G loss: 1.132988]\n",
      "614 [D loss: 0.750988, acc.: 53.12%] [G loss: 0.943307]\n",
      "615 [D loss: 0.741775, acc.: 59.38%] [G loss: 1.102611]\n",
      "616 [D loss: 0.660420, acc.: 68.75%] [G loss: 1.249958]\n",
      "617 [D loss: 0.625386, acc.: 59.38%] [G loss: 1.098703]\n",
      "618 [D loss: 0.746366, acc.: 46.88%] [G loss: 1.020949]\n",
      "619 [D loss: 0.628496, acc.: 65.62%] [G loss: 1.116843]\n",
      "620 [D loss: 0.681606, acc.: 65.62%] [G loss: 1.213565]\n",
      "621 [D loss: 0.703633, acc.: 53.12%] [G loss: 0.984249]\n",
      "622 [D loss: 0.810652, acc.: 43.75%] [G loss: 1.017600]\n",
      "623 [D loss: 0.545502, acc.: 81.25%] [G loss: 1.059489]\n",
      "624 [D loss: 0.665560, acc.: 65.62%] [G loss: 1.131129]\n",
      "625 [D loss: 0.688475, acc.: 62.50%] [G loss: 1.135223]\n",
      "626 [D loss: 0.740871, acc.: 43.75%] [G loss: 0.730919]\n",
      "627 [D loss: 0.596341, acc.: 65.62%] [G loss: 1.099471]\n",
      "628 [D loss: 0.546283, acc.: 78.12%] [G loss: 1.109518]\n",
      "629 [D loss: 0.653063, acc.: 59.38%] [G loss: 0.937908]\n",
      "630 [D loss: 0.748664, acc.: 59.38%] [G loss: 0.875127]\n",
      "631 [D loss: 0.684844, acc.: 53.12%] [G loss: 1.172932]\n",
      "632 [D loss: 0.768240, acc.: 50.00%] [G loss: 1.174513]\n",
      "633 [D loss: 0.726158, acc.: 50.00%] [G loss: 1.008961]\n",
      "634 [D loss: 0.758614, acc.: 50.00%] [G loss: 1.380044]\n",
      "635 [D loss: 0.580801, acc.: 75.00%] [G loss: 0.925739]\n",
      "636 [D loss: 0.752102, acc.: 50.00%] [G loss: 1.341276]\n",
      "637 [D loss: 0.705989, acc.: 59.38%] [G loss: 1.079352]\n",
      "638 [D loss: 0.644491, acc.: 68.75%] [G loss: 1.263615]\n",
      "639 [D loss: 0.890547, acc.: 43.75%] [G loss: 1.153961]\n",
      "640 [D loss: 0.576821, acc.: 65.62%] [G loss: 1.015366]\n",
      "641 [D loss: 0.675363, acc.: 56.25%] [G loss: 1.185271]\n",
      "642 [D loss: 0.642520, acc.: 75.00%] [G loss: 1.331989]\n",
      "643 [D loss: 0.648797, acc.: 59.38%] [G loss: 1.043377]\n",
      "644 [D loss: 0.606118, acc.: 71.88%] [G loss: 1.000761]\n",
      "645 [D loss: 0.757063, acc.: 53.12%] [G loss: 1.063067]\n",
      "646 [D loss: 0.836775, acc.: 46.88%] [G loss: 1.030914]\n",
      "647 [D loss: 0.695572, acc.: 62.50%] [G loss: 1.023146]\n",
      "648 [D loss: 0.948787, acc.: 40.62%] [G loss: 0.960423]\n",
      "649 [D loss: 0.791579, acc.: 50.00%] [G loss: 0.915323]\n",
      "650 [D loss: 0.700246, acc.: 59.38%] [G loss: 1.102575]\n",
      "651 [D loss: 0.772982, acc.: 40.62%] [G loss: 1.163125]\n",
      "652 [D loss: 0.625801, acc.: 62.50%] [G loss: 1.183205]\n",
      "653 [D loss: 0.718434, acc.: 56.25%] [G loss: 0.950362]\n",
      "654 [D loss: 0.952969, acc.: 37.50%] [G loss: 1.083487]\n",
      "655 [D loss: 0.525185, acc.: 78.12%] [G loss: 1.204779]\n",
      "656 [D loss: 1.029517, acc.: 37.50%] [G loss: 1.146086]\n",
      "657 [D loss: 0.781013, acc.: 46.88%] [G loss: 1.154734]\n",
      "658 [D loss: 0.922097, acc.: 37.50%] [G loss: 1.118861]\n",
      "659 [D loss: 0.759556, acc.: 50.00%] [G loss: 0.844240]\n",
      "660 [D loss: 0.793469, acc.: 53.12%] [G loss: 1.006147]\n",
      "661 [D loss: 0.826741, acc.: 50.00%] [G loss: 1.096406]\n",
      "662 [D loss: 0.600898, acc.: 68.75%] [G loss: 1.078584]\n",
      "663 [D loss: 0.713323, acc.: 62.50%] [G loss: 1.026879]\n",
      "664 [D loss: 0.716357, acc.: 56.25%] [G loss: 1.018232]\n",
      "665 [D loss: 0.744646, acc.: 50.00%] [G loss: 0.941159]\n",
      "666 [D loss: 0.760365, acc.: 43.75%] [G loss: 1.050068]\n",
      "667 [D loss: 0.715649, acc.: 53.12%] [G loss: 1.197136]\n",
      "668 [D loss: 0.677088, acc.: 53.12%] [G loss: 0.894368]\n",
      "669 [D loss: 0.783860, acc.: 50.00%] [G loss: 0.935982]\n",
      "670 [D loss: 0.657004, acc.: 59.38%] [G loss: 1.059183]\n",
      "671 [D loss: 0.641677, acc.: 62.50%] [G loss: 0.991152]\n",
      "672 [D loss: 0.836953, acc.: 43.75%] [G loss: 1.152345]\n",
      "673 [D loss: 0.711344, acc.: 68.75%] [G loss: 1.082882]\n",
      "674 [D loss: 0.520040, acc.: 75.00%] [G loss: 1.047523]\n",
      "675 [D loss: 0.622302, acc.: 62.50%] [G loss: 1.267553]\n",
      "676 [D loss: 0.641031, acc.: 65.62%] [G loss: 1.155251]\n",
      "677 [D loss: 0.848405, acc.: 56.25%] [G loss: 0.982149]\n",
      "678 [D loss: 0.805265, acc.: 43.75%] [G loss: 0.925923]\n",
      "679 [D loss: 0.578362, acc.: 75.00%] [G loss: 0.940847]\n",
      "680 [D loss: 0.623651, acc.: 65.62%] [G loss: 0.973600]\n",
      "681 [D loss: 0.827857, acc.: 46.88%] [G loss: 0.928161]\n",
      "682 [D loss: 0.789446, acc.: 43.75%] [G loss: 0.932237]\n",
      "683 [D loss: 0.622190, acc.: 65.62%] [G loss: 1.020200]\n",
      "684 [D loss: 0.747454, acc.: 46.88%] [G loss: 0.895423]\n",
      "685 [D loss: 0.716800, acc.: 56.25%] [G loss: 0.798451]\n",
      "686 [D loss: 0.704468, acc.: 53.12%] [G loss: 0.848935]\n",
      "687 [D loss: 0.745019, acc.: 53.12%] [G loss: 1.031700]\n",
      "688 [D loss: 0.557748, acc.: 68.75%] [G loss: 1.169700]\n",
      "689 [D loss: 0.655640, acc.: 59.38%] [G loss: 0.998285]\n",
      "690 [D loss: 0.812066, acc.: 50.00%] [G loss: 0.933982]\n",
      "691 [D loss: 0.630547, acc.: 68.75%] [G loss: 1.232236]\n",
      "692 [D loss: 0.693475, acc.: 56.25%] [G loss: 1.221151]\n",
      "693 [D loss: 0.700386, acc.: 62.50%] [G loss: 1.140341]\n",
      "694 [D loss: 0.652189, acc.: 50.00%] [G loss: 1.194686]\n",
      "695 [D loss: 0.767846, acc.: 62.50%] [G loss: 1.044975]\n",
      "696 [D loss: 0.766959, acc.: 53.12%] [G loss: 1.120746]\n",
      "697 [D loss: 0.768765, acc.: 43.75%] [G loss: 1.117614]\n",
      "698 [D loss: 0.607693, acc.: 68.75%] [G loss: 0.988118]\n",
      "699 [D loss: 0.630025, acc.: 59.38%] [G loss: 0.965425]\n",
      "700 [D loss: 0.753797, acc.: 43.75%] [G loss: 0.967277]\n",
      "701 [D loss: 0.705858, acc.: 50.00%] [G loss: 1.064055]\n",
      "702 [D loss: 0.856895, acc.: 43.75%] [G loss: 1.281249]\n",
      "703 [D loss: 0.591657, acc.: 68.75%] [G loss: 1.211896]\n",
      "704 [D loss: 0.855182, acc.: 43.75%] [G loss: 1.093770]\n",
      "705 [D loss: 0.719616, acc.: 53.12%] [G loss: 1.002019]\n",
      "706 [D loss: 0.591332, acc.: 62.50%] [G loss: 1.150875]\n",
      "707 [D loss: 0.759198, acc.: 46.88%] [G loss: 0.992276]\n",
      "708 [D loss: 0.649573, acc.: 59.38%] [G loss: 1.009514]\n",
      "709 [D loss: 0.755617, acc.: 40.62%] [G loss: 0.872763]\n",
      "710 [D loss: 0.669879, acc.: 56.25%] [G loss: 1.200440]\n",
      "711 [D loss: 0.539342, acc.: 71.88%] [G loss: 1.077061]\n",
      "712 [D loss: 0.614801, acc.: 62.50%] [G loss: 0.967826]\n",
      "713 [D loss: 0.647993, acc.: 56.25%] [G loss: 1.146830]\n",
      "714 [D loss: 0.594598, acc.: 56.25%] [G loss: 1.189831]\n",
      "715 [D loss: 0.666253, acc.: 59.38%] [G loss: 1.309338]\n",
      "716 [D loss: 0.624286, acc.: 65.62%] [G loss: 1.195271]\n",
      "717 [D loss: 0.685047, acc.: 56.25%] [G loss: 1.049430]\n",
      "718 [D loss: 0.579267, acc.: 56.25%] [G loss: 1.127374]\n",
      "719 [D loss: 0.710774, acc.: 53.12%] [G loss: 1.195198]\n",
      "720 [D loss: 0.632118, acc.: 56.25%] [G loss: 1.168589]\n",
      "721 [D loss: 0.631662, acc.: 65.62%] [G loss: 1.050536]\n",
      "722 [D loss: 0.762793, acc.: 50.00%] [G loss: 1.066097]\n",
      "723 [D loss: 0.672328, acc.: 62.50%] [G loss: 1.178156]\n",
      "724 [D loss: 0.710053, acc.: 56.25%] [G loss: 1.144182]\n",
      "725 [D loss: 0.511511, acc.: 78.12%] [G loss: 1.073912]\n",
      "726 [D loss: 0.670349, acc.: 62.50%] [G loss: 1.069801]\n",
      "727 [D loss: 0.835209, acc.: 46.88%] [G loss: 1.257293]\n",
      "728 [D loss: 0.766270, acc.: 62.50%] [G loss: 1.202602]\n",
      "729 [D loss: 0.633065, acc.: 65.62%] [G loss: 1.167165]\n",
      "730 [D loss: 0.623244, acc.: 56.25%] [G loss: 1.285290]\n",
      "731 [D loss: 0.622011, acc.: 59.38%] [G loss: 1.216926]\n",
      "732 [D loss: 0.728200, acc.: 50.00%] [G loss: 1.054903]\n",
      "733 [D loss: 0.728457, acc.: 43.75%] [G loss: 0.855952]\n",
      "734 [D loss: 0.704873, acc.: 46.88%] [G loss: 1.123433]\n",
      "735 [D loss: 0.663703, acc.: 65.62%] [G loss: 1.206283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736 [D loss: 0.725816, acc.: 56.25%] [G loss: 1.165334]\n",
      "737 [D loss: 0.758255, acc.: 50.00%] [G loss: 1.098618]\n",
      "738 [D loss: 0.634849, acc.: 65.62%] [G loss: 1.169750]\n",
      "739 [D loss: 0.941012, acc.: 28.12%] [G loss: 1.097910]\n",
      "740 [D loss: 0.680269, acc.: 59.38%] [G loss: 1.177458]\n",
      "741 [D loss: 0.663250, acc.: 59.38%] [G loss: 1.272601]\n",
      "742 [D loss: 0.591402, acc.: 71.88%] [G loss: 1.088375]\n",
      "743 [D loss: 0.733512, acc.: 50.00%] [G loss: 0.994327]\n",
      "744 [D loss: 0.638064, acc.: 62.50%] [G loss: 0.968140]\n",
      "745 [D loss: 0.677482, acc.: 65.62%] [G loss: 0.914111]\n",
      "746 [D loss: 0.621108, acc.: 71.88%] [G loss: 0.880786]\n",
      "747 [D loss: 0.552331, acc.: 71.88%] [G loss: 1.007498]\n",
      "748 [D loss: 0.786966, acc.: 50.00%] [G loss: 0.998402]\n",
      "749 [D loss: 0.551716, acc.: 75.00%] [G loss: 1.255609]\n",
      "750 [D loss: 0.765745, acc.: 50.00%] [G loss: 1.068562]\n",
      "751 [D loss: 0.737207, acc.: 59.38%] [G loss: 1.236624]\n",
      "752 [D loss: 0.767151, acc.: 46.88%] [G loss: 1.055738]\n",
      "753 [D loss: 0.721354, acc.: 56.25%] [G loss: 1.274062]\n",
      "754 [D loss: 0.697794, acc.: 62.50%] [G loss: 1.134808]\n",
      "755 [D loss: 0.745245, acc.: 59.38%] [G loss: 0.906436]\n",
      "756 [D loss: 0.731987, acc.: 53.12%] [G loss: 0.818540]\n",
      "757 [D loss: 0.654575, acc.: 56.25%] [G loss: 0.916810]\n",
      "758 [D loss: 0.784037, acc.: 56.25%] [G loss: 0.942549]\n",
      "759 [D loss: 0.744111, acc.: 46.88%] [G loss: 0.858406]\n",
      "760 [D loss: 0.688866, acc.: 56.25%] [G loss: 0.935351]\n",
      "761 [D loss: 0.692515, acc.: 62.50%] [G loss: 1.150720]\n",
      "762 [D loss: 0.534912, acc.: 78.12%] [G loss: 1.143929]\n",
      "763 [D loss: 0.686483, acc.: 53.12%] [G loss: 0.950167]\n",
      "764 [D loss: 0.702419, acc.: 50.00%] [G loss: 1.109056]\n",
      "765 [D loss: 0.627066, acc.: 65.62%] [G loss: 1.046841]\n",
      "766 [D loss: 0.753591, acc.: 50.00%] [G loss: 0.984274]\n",
      "767 [D loss: 0.722546, acc.: 53.12%] [G loss: 0.997922]\n",
      "768 [D loss: 0.733022, acc.: 59.38%] [G loss: 1.065562]\n",
      "769 [D loss: 0.711042, acc.: 59.38%] [G loss: 0.930199]\n",
      "770 [D loss: 0.710147, acc.: 62.50%] [G loss: 0.826534]\n",
      "771 [D loss: 0.716520, acc.: 50.00%] [G loss: 1.064094]\n",
      "772 [D loss: 0.734082, acc.: 59.38%] [G loss: 1.064337]\n",
      "773 [D loss: 0.782468, acc.: 56.25%] [G loss: 1.277301]\n",
      "774 [D loss: 0.583013, acc.: 71.88%] [G loss: 1.043379]\n",
      "775 [D loss: 0.734154, acc.: 65.62%] [G loss: 1.189084]\n",
      "776 [D loss: 0.745638, acc.: 59.38%] [G loss: 1.074556]\n",
      "777 [D loss: 0.723361, acc.: 43.75%] [G loss: 1.177211]\n",
      "778 [D loss: 0.673808, acc.: 59.38%] [G loss: 1.159589]\n",
      "779 [D loss: 0.858231, acc.: 40.62%] [G loss: 1.086930]\n",
      "780 [D loss: 0.541924, acc.: 68.75%] [G loss: 1.165130]\n",
      "781 [D loss: 0.872177, acc.: 43.75%] [G loss: 0.831897]\n",
      "782 [D loss: 0.809812, acc.: 40.62%] [G loss: 0.893756]\n",
      "783 [D loss: 0.713861, acc.: 46.88%] [G loss: 0.950952]\n",
      "784 [D loss: 0.611461, acc.: 65.62%] [G loss: 1.146719]\n",
      "785 [D loss: 0.681499, acc.: 50.00%] [G loss: 1.035246]\n",
      "786 [D loss: 0.693061, acc.: 59.38%] [G loss: 1.074183]\n",
      "787 [D loss: 0.715615, acc.: 56.25%] [G loss: 1.221229]\n",
      "788 [D loss: 0.640782, acc.: 65.62%] [G loss: 0.986815]\n",
      "789 [D loss: 0.617432, acc.: 75.00%] [G loss: 1.130858]\n",
      "790 [D loss: 0.798113, acc.: 50.00%] [G loss: 1.163064]\n",
      "791 [D loss: 0.631224, acc.: 62.50%] [G loss: 1.097520]\n",
      "792 [D loss: 0.928261, acc.: 31.25%] [G loss: 0.995365]\n",
      "793 [D loss: 0.879010, acc.: 34.38%] [G loss: 1.012114]\n",
      "794 [D loss: 0.505396, acc.: 87.50%] [G loss: 1.286082]\n",
      "795 [D loss: 0.668040, acc.: 68.75%] [G loss: 1.097340]\n",
      "796 [D loss: 0.637676, acc.: 59.38%] [G loss: 1.133433]\n",
      "797 [D loss: 0.710212, acc.: 56.25%] [G loss: 1.017361]\n",
      "798 [D loss: 0.676073, acc.: 53.12%] [G loss: 0.998088]\n",
      "799 [D loss: 0.658443, acc.: 53.12%] [G loss: 0.944057]\n",
      "800 [D loss: 0.804059, acc.: 40.62%] [G loss: 0.865128]\n",
      "801 [D loss: 0.635381, acc.: 68.75%] [G loss: 1.306188]\n",
      "802 [D loss: 0.760991, acc.: 53.12%] [G loss: 1.016193]\n",
      "803 [D loss: 0.719229, acc.: 53.12%] [G loss: 1.361882]\n",
      "804 [D loss: 0.758172, acc.: 40.62%] [G loss: 0.907824]\n",
      "805 [D loss: 0.720925, acc.: 59.38%] [G loss: 0.840392]\n",
      "806 [D loss: 0.702252, acc.: 53.12%] [G loss: 1.087656]\n",
      "807 [D loss: 0.716998, acc.: 62.50%] [G loss: 0.934352]\n",
      "808 [D loss: 0.692693, acc.: 50.00%] [G loss: 1.079638]\n",
      "809 [D loss: 0.812422, acc.: 46.88%] [G loss: 0.900211]\n",
      "810 [D loss: 0.718007, acc.: 53.12%] [G loss: 1.048548]\n",
      "811 [D loss: 0.707221, acc.: 59.38%] [G loss: 0.967084]\n",
      "812 [D loss: 0.788181, acc.: 43.75%] [G loss: 0.939047]\n",
      "813 [D loss: 0.604073, acc.: 65.62%] [G loss: 0.961876]\n",
      "814 [D loss: 0.645560, acc.: 56.25%] [G loss: 1.197924]\n",
      "815 [D loss: 0.593591, acc.: 65.62%] [G loss: 1.264133]\n",
      "816 [D loss: 0.773320, acc.: 62.50%] [G loss: 1.137644]\n",
      "817 [D loss: 0.698298, acc.: 50.00%] [G loss: 1.012435]\n",
      "818 [D loss: 0.804282, acc.: 53.12%] [G loss: 1.335748]\n",
      "819 [D loss: 0.531559, acc.: 68.75%] [G loss: 1.350505]\n",
      "820 [D loss: 0.973978, acc.: 40.62%] [G loss: 1.147206]\n",
      "821 [D loss: 0.924283, acc.: 43.75%] [G loss: 0.971921]\n",
      "822 [D loss: 0.653019, acc.: 56.25%] [G loss: 1.126462]\n",
      "823 [D loss: 0.598658, acc.: 71.88%] [G loss: 1.223900]\n",
      "824 [D loss: 0.780025, acc.: 56.25%] [G loss: 1.117147]\n",
      "825 [D loss: 0.721823, acc.: 56.25%] [G loss: 0.998294]\n",
      "826 [D loss: 0.645000, acc.: 62.50%] [G loss: 1.203395]\n",
      "827 [D loss: 0.874062, acc.: 46.88%] [G loss: 1.154752]\n",
      "828 [D loss: 0.734802, acc.: 46.88%] [G loss: 1.002759]\n",
      "829 [D loss: 0.845503, acc.: 46.88%] [G loss: 1.100673]\n",
      "830 [D loss: 0.720021, acc.: 53.12%] [G loss: 1.136173]\n",
      "831 [D loss: 0.812267, acc.: 46.88%] [G loss: 1.076032]\n",
      "832 [D loss: 0.627801, acc.: 68.75%] [G loss: 1.065269]\n",
      "833 [D loss: 0.722249, acc.: 59.38%] [G loss: 1.110306]\n",
      "834 [D loss: 0.754605, acc.: 46.88%] [G loss: 1.143527]\n",
      "835 [D loss: 0.843099, acc.: 46.88%] [G loss: 1.095031]\n",
      "836 [D loss: 0.667950, acc.: 56.25%] [G loss: 1.194634]\n",
      "837 [D loss: 0.559632, acc.: 68.75%] [G loss: 1.275466]\n",
      "838 [D loss: 0.576075, acc.: 59.38%] [G loss: 1.040769]\n",
      "839 [D loss: 0.572973, acc.: 65.62%] [G loss: 1.329418]\n",
      "840 [D loss: 0.660618, acc.: 59.38%] [G loss: 1.330355]\n",
      "841 [D loss: 0.778507, acc.: 56.25%] [G loss: 1.192642]\n",
      "842 [D loss: 0.700838, acc.: 56.25%] [G loss: 1.228267]\n",
      "843 [D loss: 0.970708, acc.: 43.75%] [G loss: 1.138856]\n",
      "844 [D loss: 1.033576, acc.: 25.00%] [G loss: 1.142959]\n",
      "845 [D loss: 0.785261, acc.: 53.12%] [G loss: 1.151751]\n",
      "846 [D loss: 0.740295, acc.: 59.38%] [G loss: 1.021814]\n",
      "847 [D loss: 0.587522, acc.: 75.00%] [G loss: 1.181438]\n",
      "848 [D loss: 0.668668, acc.: 59.38%] [G loss: 1.171212]\n",
      "849 [D loss: 0.610865, acc.: 65.62%] [G loss: 1.072395]\n",
      "850 [D loss: 0.616734, acc.: 62.50%] [G loss: 0.917120]\n",
      "851 [D loss: 0.568899, acc.: 65.62%] [G loss: 1.037787]\n",
      "852 [D loss: 0.803122, acc.: 40.62%] [G loss: 0.959391]\n",
      "853 [D loss: 0.715078, acc.: 56.25%] [G loss: 0.971920]\n",
      "854 [D loss: 0.819033, acc.: 34.38%] [G loss: 1.147208]\n",
      "855 [D loss: 0.624900, acc.: 75.00%] [G loss: 1.141696]\n",
      "856 [D loss: 0.563877, acc.: 81.25%] [G loss: 1.200966]\n",
      "857 [D loss: 0.792407, acc.: 56.25%] [G loss: 1.062501]\n",
      "858 [D loss: 0.573581, acc.: 75.00%] [G loss: 0.982984]\n",
      "859 [D loss: 0.721211, acc.: 50.00%] [G loss: 1.043401]\n",
      "860 [D loss: 0.620177, acc.: 56.25%] [G loss: 1.152847]\n",
      "861 [D loss: 0.604249, acc.: 71.88%] [G loss: 1.235160]\n",
      "862 [D loss: 0.624946, acc.: 62.50%] [G loss: 1.255765]\n",
      "863 [D loss: 0.565058, acc.: 68.75%] [G loss: 1.165522]\n",
      "864 [D loss: 0.636191, acc.: 68.75%] [G loss: 0.949019]\n",
      "865 [D loss: 0.819740, acc.: 40.62%] [G loss: 1.131049]\n",
      "866 [D loss: 0.639607, acc.: 62.50%] [G loss: 0.970400]\n",
      "867 [D loss: 0.903263, acc.: 37.50%] [G loss: 0.908599]\n",
      "868 [D loss: 0.570678, acc.: 65.62%] [G loss: 0.989640]\n",
      "869 [D loss: 0.727900, acc.: 50.00%] [G loss: 1.100363]\n",
      "870 [D loss: 0.716383, acc.: 56.25%] [G loss: 1.057046]\n",
      "871 [D loss: 0.666622, acc.: 65.62%] [G loss: 1.152968]\n",
      "872 [D loss: 0.787639, acc.: 68.75%] [G loss: 1.214287]\n",
      "873 [D loss: 0.731247, acc.: 56.25%] [G loss: 0.905698]\n",
      "874 [D loss: 0.650960, acc.: 59.38%] [G loss: 0.888186]\n",
      "875 [D loss: 0.735600, acc.: 53.12%] [G loss: 0.989208]\n",
      "876 [D loss: 0.569057, acc.: 65.62%] [G loss: 1.062373]\n",
      "877 [D loss: 0.764207, acc.: 50.00%] [G loss: 0.968399]\n",
      "878 [D loss: 0.715965, acc.: 50.00%] [G loss: 0.964865]\n",
      "879 [D loss: 0.785741, acc.: 46.88%] [G loss: 1.220472]\n",
      "880 [D loss: 0.549325, acc.: 78.12%] [G loss: 0.994545]\n",
      "881 [D loss: 0.684607, acc.: 65.62%] [G loss: 1.006320]\n",
      "882 [D loss: 0.533908, acc.: 71.88%] [G loss: 1.299488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883 [D loss: 0.703092, acc.: 71.88%] [G loss: 1.106139]\n",
      "884 [D loss: 0.763608, acc.: 56.25%] [G loss: 1.060137]\n",
      "885 [D loss: 0.616509, acc.: 62.50%] [G loss: 1.180697]\n",
      "886 [D loss: 0.687232, acc.: 53.12%] [G loss: 1.057596]\n",
      "887 [D loss: 0.746968, acc.: 46.88%] [G loss: 1.134124]\n",
      "888 [D loss: 0.510930, acc.: 78.12%] [G loss: 1.290586]\n",
      "889 [D loss: 0.578120, acc.: 71.88%] [G loss: 1.154976]\n",
      "890 [D loss: 0.819487, acc.: 50.00%] [G loss: 1.111248]\n",
      "891 [D loss: 0.752123, acc.: 50.00%] [G loss: 0.940510]\n",
      "892 [D loss: 0.588479, acc.: 65.62%] [G loss: 0.975456]\n",
      "893 [D loss: 0.625385, acc.: 68.75%] [G loss: 1.140030]\n",
      "894 [D loss: 0.623186, acc.: 59.38%] [G loss: 1.060191]\n",
      "895 [D loss: 0.682636, acc.: 68.75%] [G loss: 1.031966]\n",
      "896 [D loss: 0.713643, acc.: 65.62%] [G loss: 0.944053]\n",
      "897 [D loss: 0.685254, acc.: 65.62%] [G loss: 1.131845]\n",
      "898 [D loss: 0.704014, acc.: 62.50%] [G loss: 1.091805]\n",
      "899 [D loss: 0.716679, acc.: 50.00%] [G loss: 1.064402]\n",
      "900 [D loss: 0.672711, acc.: 59.38%] [G loss: 1.204390]\n",
      "901 [D loss: 0.550853, acc.: 71.88%] [G loss: 1.213420]\n",
      "902 [D loss: 0.626092, acc.: 62.50%] [G loss: 1.140919]\n",
      "903 [D loss: 0.579865, acc.: 75.00%] [G loss: 0.870314]\n",
      "904 [D loss: 0.671502, acc.: 56.25%] [G loss: 0.746139]\n",
      "905 [D loss: 0.537454, acc.: 65.62%] [G loss: 0.901123]\n",
      "906 [D loss: 0.747836, acc.: 46.88%] [G loss: 0.933260]\n",
      "907 [D loss: 0.658510, acc.: 56.25%] [G loss: 0.868365]\n",
      "908 [D loss: 0.673229, acc.: 68.75%] [G loss: 0.972773]\n",
      "909 [D loss: 0.609653, acc.: 68.75%] [G loss: 0.976417]\n",
      "910 [D loss: 0.625624, acc.: 62.50%] [G loss: 0.992849]\n",
      "911 [D loss: 0.720740, acc.: 56.25%] [G loss: 1.040625]\n",
      "912 [D loss: 0.768862, acc.: 50.00%] [G loss: 1.209462]\n",
      "913 [D loss: 0.814194, acc.: 46.88%] [G loss: 0.958385]\n",
      "914 [D loss: 0.789848, acc.: 43.75%] [G loss: 0.982559]\n",
      "915 [D loss: 0.759452, acc.: 50.00%] [G loss: 1.234606]\n",
      "916 [D loss: 0.816489, acc.: 46.88%] [G loss: 1.006775]\n",
      "917 [D loss: 0.679715, acc.: 53.12%] [G loss: 1.097864]\n",
      "918 [D loss: 0.648013, acc.: 59.38%] [G loss: 1.004932]\n",
      "919 [D loss: 0.727185, acc.: 59.38%] [G loss: 0.853338]\n",
      "920 [D loss: 0.545555, acc.: 78.12%] [G loss: 1.001665]\n",
      "921 [D loss: 0.770965, acc.: 46.88%] [G loss: 1.075103]\n",
      "922 [D loss: 0.664072, acc.: 59.38%] [G loss: 1.043377]\n",
      "923 [D loss: 0.669018, acc.: 56.25%] [G loss: 1.163427]\n",
      "924 [D loss: 0.679162, acc.: 65.62%] [G loss: 1.067087]\n",
      "925 [D loss: 0.523068, acc.: 71.88%] [G loss: 1.238275]\n",
      "926 [D loss: 0.806611, acc.: 43.75%] [G loss: 1.111614]\n",
      "927 [D loss: 0.664807, acc.: 59.38%] [G loss: 1.203781]\n",
      "928 [D loss: 0.636177, acc.: 56.25%] [G loss: 1.189425]\n",
      "929 [D loss: 0.627249, acc.: 62.50%] [G loss: 1.017772]\n",
      "930 [D loss: 0.706469, acc.: 56.25%] [G loss: 1.236055]\n",
      "931 [D loss: 0.718629, acc.: 53.12%] [G loss: 1.258946]\n",
      "932 [D loss: 0.750633, acc.: 56.25%] [G loss: 1.016508]\n",
      "933 [D loss: 0.748498, acc.: 46.88%] [G loss: 1.167544]\n",
      "934 [D loss: 0.690893, acc.: 53.12%] [G loss: 1.074012]\n",
      "935 [D loss: 0.708959, acc.: 53.12%] [G loss: 0.978976]\n",
      "936 [D loss: 0.625013, acc.: 71.88%] [G loss: 1.195621]\n",
      "937 [D loss: 0.822208, acc.: 43.75%] [G loss: 1.034088]\n",
      "938 [D loss: 0.703556, acc.: 53.12%] [G loss: 1.165604]\n",
      "939 [D loss: 0.699112, acc.: 50.00%] [G loss: 1.172079]\n",
      "940 [D loss: 0.487112, acc.: 68.75%] [G loss: 1.237398]\n",
      "941 [D loss: 0.669342, acc.: 62.50%] [G loss: 1.233950]\n",
      "942 [D loss: 0.725446, acc.: 59.38%] [G loss: 1.284783]\n",
      "943 [D loss: 0.630015, acc.: 71.88%] [G loss: 1.232344]\n",
      "944 [D loss: 0.864611, acc.: 43.75%] [G loss: 1.170843]\n",
      "945 [D loss: 0.637929, acc.: 65.62%] [G loss: 1.199103]\n",
      "946 [D loss: 0.703063, acc.: 53.12%] [G loss: 1.164748]\n",
      "947 [D loss: 0.636870, acc.: 59.38%] [G loss: 1.231276]\n",
      "948 [D loss: 0.649127, acc.: 65.62%] [G loss: 1.159642]\n",
      "949 [D loss: 0.707516, acc.: 53.12%] [G loss: 1.102418]\n",
      "950 [D loss: 0.682510, acc.: 56.25%] [G loss: 1.113500]\n",
      "951 [D loss: 0.651083, acc.: 56.25%] [G loss: 1.208951]\n",
      "952 [D loss: 0.763695, acc.: 56.25%] [G loss: 1.009453]\n",
      "953 [D loss: 0.688272, acc.: 59.38%] [G loss: 1.123973]\n",
      "954 [D loss: 0.688689, acc.: 68.75%] [G loss: 1.179353]\n",
      "955 [D loss: 0.666708, acc.: 56.25%] [G loss: 1.258386]\n",
      "956 [D loss: 0.610115, acc.: 65.62%] [G loss: 1.050195]\n",
      "957 [D loss: 0.727675, acc.: 56.25%] [G loss: 0.900373]\n",
      "958 [D loss: 0.637382, acc.: 65.62%] [G loss: 0.920996]\n",
      "959 [D loss: 0.537538, acc.: 81.25%] [G loss: 0.900637]\n",
      "960 [D loss: 0.639606, acc.: 56.25%] [G loss: 1.023524]\n",
      "961 [D loss: 0.502074, acc.: 78.12%] [G loss: 1.069653]\n",
      "962 [D loss: 0.569545, acc.: 68.75%] [G loss: 0.939696]\n",
      "963 [D loss: 0.822318, acc.: 46.88%] [G loss: 0.968138]\n",
      "964 [D loss: 0.579825, acc.: 68.75%] [G loss: 1.128855]\n",
      "965 [D loss: 0.666764, acc.: 75.00%] [G loss: 1.190602]\n",
      "966 [D loss: 0.638229, acc.: 62.50%] [G loss: 1.225610]\n",
      "967 [D loss: 0.719537, acc.: 53.12%] [G loss: 1.081838]\n",
      "968 [D loss: 0.772258, acc.: 40.62%] [G loss: 0.977329]\n",
      "969 [D loss: 0.751077, acc.: 53.12%] [G loss: 1.082046]\n",
      "970 [D loss: 0.594439, acc.: 71.88%] [G loss: 1.259828]\n",
      "971 [D loss: 0.818558, acc.: 53.12%] [G loss: 1.022170]\n",
      "972 [D loss: 0.670320, acc.: 62.50%] [G loss: 1.121392]\n",
      "973 [D loss: 0.772551, acc.: 50.00%] [G loss: 1.241444]\n",
      "974 [D loss: 0.572148, acc.: 71.88%] [G loss: 1.220757]\n",
      "975 [D loss: 0.668560, acc.: 65.62%] [G loss: 1.141174]\n",
      "976 [D loss: 0.620024, acc.: 56.25%] [G loss: 1.081569]\n",
      "977 [D loss: 0.911691, acc.: 40.62%] [G loss: 1.041958]\n",
      "978 [D loss: 0.817901, acc.: 53.12%] [G loss: 0.965385]\n",
      "979 [D loss: 0.578070, acc.: 68.75%] [G loss: 0.930177]\n",
      "980 [D loss: 0.705506, acc.: 62.50%] [G loss: 0.966366]\n",
      "981 [D loss: 0.612015, acc.: 68.75%] [G loss: 1.168680]\n",
      "982 [D loss: 0.608102, acc.: 65.62%] [G loss: 1.195663]\n",
      "983 [D loss: 0.589090, acc.: 62.50%] [G loss: 1.011290]\n",
      "984 [D loss: 0.658422, acc.: 59.38%] [G loss: 1.119837]\n",
      "985 [D loss: 0.779802, acc.: 59.38%] [G loss: 0.829798]\n",
      "986 [D loss: 0.767691, acc.: 59.38%] [G loss: 1.075322]\n",
      "987 [D loss: 0.592237, acc.: 78.12%] [G loss: 0.951342]\n",
      "988 [D loss: 0.665545, acc.: 65.62%] [G loss: 1.043256]\n",
      "989 [D loss: 0.723276, acc.: 56.25%] [G loss: 1.117593]\n",
      "990 [D loss: 0.533065, acc.: 71.88%] [G loss: 1.180480]\n",
      "991 [D loss: 0.674451, acc.: 68.75%] [G loss: 1.267687]\n",
      "992 [D loss: 0.663136, acc.: 59.38%] [G loss: 1.389219]\n",
      "993 [D loss: 0.580595, acc.: 71.88%] [G loss: 0.885782]\n",
      "994 [D loss: 0.588923, acc.: 68.75%] [G loss: 1.099502]\n",
      "995 [D loss: 0.682418, acc.: 65.62%] [G loss: 1.061641]\n",
      "996 [D loss: 0.746230, acc.: 56.25%] [G loss: 1.154835]\n",
      "997 [D loss: 0.589878, acc.: 75.00%] [G loss: 1.074560]\n",
      "998 [D loss: 0.672692, acc.: 46.88%] [G loss: 1.109635]\n",
      "999 [D loss: 0.682887, acc.: 59.38%] [G loss: 1.103767]\n",
      "1000 [D loss: 0.761094, acc.: 53.12%] [G loss: 0.904118]\n",
      "1001 [D loss: 0.703907, acc.: 53.12%] [G loss: 1.024698]\n",
      "1002 [D loss: 0.809888, acc.: 43.75%] [G loss: 1.054581]\n",
      "1003 [D loss: 0.529810, acc.: 81.25%] [G loss: 1.041758]\n",
      "1004 [D loss: 0.660029, acc.: 59.38%] [G loss: 1.044115]\n",
      "1005 [D loss: 0.775903, acc.: 53.12%] [G loss: 1.171132]\n",
      "1006 [D loss: 0.705910, acc.: 59.38%] [G loss: 1.145385]\n",
      "1007 [D loss: 0.610358, acc.: 65.62%] [G loss: 1.098524]\n",
      "1008 [D loss: 0.752678, acc.: 59.38%] [G loss: 1.043785]\n",
      "1009 [D loss: 0.625762, acc.: 65.62%] [G loss: 1.027317]\n",
      "1010 [D loss: 0.641963, acc.: 71.88%] [G loss: 1.049227]\n",
      "1011 [D loss: 0.774852, acc.: 50.00%] [G loss: 1.119031]\n",
      "1012 [D loss: 0.752641, acc.: 43.75%] [G loss: 1.151832]\n",
      "1013 [D loss: 0.722012, acc.: 56.25%] [G loss: 1.199061]\n",
      "1014 [D loss: 0.696302, acc.: 56.25%] [G loss: 1.186256]\n",
      "1015 [D loss: 0.731619, acc.: 59.38%] [G loss: 1.134445]\n",
      "1016 [D loss: 0.774734, acc.: 50.00%] [G loss: 1.128152]\n",
      "1017 [D loss: 0.715424, acc.: 56.25%] [G loss: 1.020237]\n",
      "1018 [D loss: 0.624425, acc.: 56.25%] [G loss: 1.154651]\n",
      "1019 [D loss: 0.763946, acc.: 50.00%] [G loss: 1.272614]\n",
      "1020 [D loss: 0.639802, acc.: 56.25%] [G loss: 1.060625]\n",
      "1021 [D loss: 0.582325, acc.: 75.00%] [G loss: 1.088735]\n",
      "1022 [D loss: 0.652745, acc.: 68.75%] [G loss: 1.092853]\n",
      "1023 [D loss: 0.559330, acc.: 71.88%] [G loss: 1.057107]\n",
      "1024 [D loss: 0.602150, acc.: 65.62%] [G loss: 1.197828]\n",
      "1025 [D loss: 0.666516, acc.: 53.12%] [G loss: 1.132671]\n",
      "1026 [D loss: 0.737849, acc.: 56.25%] [G loss: 1.178960]\n",
      "1027 [D loss: 0.833222, acc.: 46.88%] [G loss: 1.004627]\n",
      "1028 [D loss: 0.802925, acc.: 43.75%] [G loss: 1.083785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029 [D loss: 0.710681, acc.: 59.38%] [G loss: 0.968496]\n",
      "1030 [D loss: 0.808363, acc.: 37.50%] [G loss: 0.921353]\n",
      "1031 [D loss: 0.748870, acc.: 56.25%] [G loss: 1.061141]\n",
      "1032 [D loss: 0.589093, acc.: 68.75%] [G loss: 1.264704]\n",
      "1033 [D loss: 0.688039, acc.: 53.12%] [G loss: 1.167070]\n",
      "1034 [D loss: 0.670684, acc.: 68.75%] [G loss: 1.151988]\n",
      "1035 [D loss: 0.847104, acc.: 46.88%] [G loss: 0.975869]\n",
      "1036 [D loss: 0.613431, acc.: 56.25%] [G loss: 0.980566]\n",
      "1037 [D loss: 0.676505, acc.: 68.75%] [G loss: 0.842162]\n",
      "1038 [D loss: 0.605374, acc.: 62.50%] [G loss: 1.026921]\n",
      "1039 [D loss: 0.725711, acc.: 50.00%] [G loss: 1.154741]\n",
      "1040 [D loss: 0.626918, acc.: 59.38%] [G loss: 1.012131]\n",
      "1041 [D loss: 0.666154, acc.: 56.25%] [G loss: 0.985498]\n",
      "1042 [D loss: 0.492538, acc.: 78.12%] [G loss: 1.125892]\n",
      "1043 [D loss: 0.580642, acc.: 68.75%] [G loss: 1.189940]\n",
      "1044 [D loss: 0.622464, acc.: 71.88%] [G loss: 1.074337]\n",
      "1045 [D loss: 0.651704, acc.: 62.50%] [G loss: 1.079228]\n",
      "1046 [D loss: 0.918623, acc.: 37.50%] [G loss: 1.175400]\n",
      "1047 [D loss: 0.552464, acc.: 65.62%] [G loss: 0.808429]\n",
      "1048 [D loss: 0.644981, acc.: 71.88%] [G loss: 0.918829]\n",
      "1049 [D loss: 0.670855, acc.: 56.25%] [G loss: 1.098998]\n",
      "1050 [D loss: 0.368597, acc.: 93.75%] [G loss: 1.018803]\n",
      "1051 [D loss: 0.677622, acc.: 62.50%] [G loss: 0.935533]\n",
      "1052 [D loss: 0.664078, acc.: 62.50%] [G loss: 1.039309]\n",
      "1053 [D loss: 0.771384, acc.: 56.25%] [G loss: 1.286363]\n",
      "1054 [D loss: 0.567682, acc.: 71.88%] [G loss: 1.268262]\n",
      "1055 [D loss: 0.641687, acc.: 56.25%] [G loss: 1.176159]\n",
      "1056 [D loss: 0.646168, acc.: 62.50%] [G loss: 0.912600]\n",
      "1057 [D loss: 0.705465, acc.: 53.12%] [G loss: 0.710023]\n",
      "1058 [D loss: 0.710310, acc.: 56.25%] [G loss: 1.054079]\n",
      "1059 [D loss: 0.709690, acc.: 56.25%] [G loss: 1.226302]\n",
      "1060 [D loss: 0.730093, acc.: 46.88%] [G loss: 1.147406]\n",
      "1061 [D loss: 0.737417, acc.: 46.88%] [G loss: 0.971552]\n",
      "1062 [D loss: 0.615714, acc.: 75.00%] [G loss: 1.245610]\n",
      "1063 [D loss: 0.845656, acc.: 50.00%] [G loss: 0.860862]\n",
      "1064 [D loss: 0.583455, acc.: 78.12%] [G loss: 0.961868]\n",
      "1065 [D loss: 0.599947, acc.: 65.62%] [G loss: 0.977600]\n",
      "1066 [D loss: 0.661982, acc.: 68.75%] [G loss: 1.074504]\n",
      "1067 [D loss: 0.773793, acc.: 59.38%] [G loss: 1.262451]\n",
      "1068 [D loss: 0.635845, acc.: 59.38%] [G loss: 1.033345]\n",
      "1069 [D loss: 0.770391, acc.: 46.88%] [G loss: 1.059652]\n",
      "1070 [D loss: 0.666783, acc.: 62.50%] [G loss: 1.043994]\n",
      "1071 [D loss: 0.523993, acc.: 84.38%] [G loss: 0.988838]\n",
      "1072 [D loss: 0.826355, acc.: 46.88%] [G loss: 1.058380]\n",
      "1073 [D loss: 0.610771, acc.: 71.88%] [G loss: 1.246104]\n",
      "1074 [D loss: 0.728640, acc.: 50.00%] [G loss: 1.180468]\n",
      "1075 [D loss: 0.734211, acc.: 53.12%] [G loss: 1.046532]\n",
      "1076 [D loss: 0.800808, acc.: 46.88%] [G loss: 1.190365]\n",
      "1077 [D loss: 0.608806, acc.: 65.62%] [G loss: 0.879396]\n",
      "1078 [D loss: 0.774713, acc.: 43.75%] [G loss: 0.837712]\n",
      "1079 [D loss: 0.611702, acc.: 65.62%] [G loss: 1.025544]\n",
      "1080 [D loss: 0.810632, acc.: 34.38%] [G loss: 1.079601]\n",
      "1081 [D loss: 0.690322, acc.: 56.25%] [G loss: 0.949669]\n",
      "1082 [D loss: 0.827158, acc.: 40.62%] [G loss: 1.093657]\n",
      "1083 [D loss: 0.655209, acc.: 50.00%] [G loss: 1.286025]\n",
      "1084 [D loss: 0.745693, acc.: 46.88%] [G loss: 1.002904]\n",
      "1085 [D loss: 0.750274, acc.: 56.25%] [G loss: 1.118167]\n",
      "1086 [D loss: 0.760334, acc.: 56.25%] [G loss: 1.059308]\n",
      "1087 [D loss: 0.560617, acc.: 68.75%] [G loss: 1.219573]\n",
      "1088 [D loss: 0.645823, acc.: 65.62%] [G loss: 1.017415]\n",
      "1089 [D loss: 0.884834, acc.: 50.00%] [G loss: 1.046356]\n",
      "1090 [D loss: 0.702393, acc.: 53.12%] [G loss: 0.870794]\n",
      "1091 [D loss: 0.763383, acc.: 46.88%] [G loss: 0.913208]\n",
      "1092 [D loss: 0.698883, acc.: 53.12%] [G loss: 0.981544]\n",
      "1093 [D loss: 0.639860, acc.: 65.62%] [G loss: 1.012575]\n",
      "1094 [D loss: 0.698637, acc.: 65.62%] [G loss: 0.983254]\n",
      "1095 [D loss: 0.586216, acc.: 62.50%] [G loss: 1.109988]\n",
      "1096 [D loss: 0.683468, acc.: 53.12%] [G loss: 1.096092]\n",
      "1097 [D loss: 0.684517, acc.: 56.25%] [G loss: 1.063387]\n",
      "1098 [D loss: 0.759692, acc.: 53.12%] [G loss: 1.184327]\n",
      "1099 [D loss: 0.540406, acc.: 78.12%] [G loss: 0.998718]\n",
      "1100 [D loss: 0.660281, acc.: 56.25%] [G loss: 1.036785]\n",
      "1101 [D loss: 0.709921, acc.: 59.38%] [G loss: 1.095697]\n",
      "1102 [D loss: 0.706163, acc.: 53.12%] [G loss: 0.940093]\n",
      "1103 [D loss: 0.739486, acc.: 50.00%] [G loss: 1.175364]\n",
      "1104 [D loss: 0.764282, acc.: 62.50%] [G loss: 1.069086]\n",
      "1105 [D loss: 0.628384, acc.: 71.88%] [G loss: 0.933364]\n",
      "1106 [D loss: 0.572487, acc.: 68.75%] [G loss: 0.923462]\n",
      "1107 [D loss: 0.747949, acc.: 59.38%] [G loss: 1.128355]\n",
      "1108 [D loss: 0.560013, acc.: 78.12%] [G loss: 1.262975]\n",
      "1109 [D loss: 0.629543, acc.: 71.88%] [G loss: 1.047629]\n",
      "1110 [D loss: 0.652021, acc.: 56.25%] [G loss: 1.251498]\n",
      "1111 [D loss: 0.779880, acc.: 40.62%] [G loss: 0.981736]\n",
      "1112 [D loss: 0.778701, acc.: 40.62%] [G loss: 1.198414]\n",
      "1113 [D loss: 0.475916, acc.: 81.25%] [G loss: 1.151788]\n",
      "1114 [D loss: 0.625726, acc.: 65.62%] [G loss: 0.942250]\n",
      "1115 [D loss: 0.603613, acc.: 65.62%] [G loss: 1.143440]\n",
      "1116 [D loss: 0.706366, acc.: 62.50%] [G loss: 1.155075]\n",
      "1117 [D loss: 0.948706, acc.: 46.88%] [G loss: 1.123788]\n",
      "1118 [D loss: 0.760074, acc.: 50.00%] [G loss: 0.980624]\n",
      "1119 [D loss: 0.727915, acc.: 59.38%] [G loss: 0.840707]\n",
      "1120 [D loss: 0.621253, acc.: 71.88%] [G loss: 1.087123]\n",
      "1121 [D loss: 0.726664, acc.: 43.75%] [G loss: 0.923327]\n",
      "1122 [D loss: 0.746495, acc.: 53.12%] [G loss: 1.093086]\n",
      "1123 [D loss: 0.591046, acc.: 68.75%] [G loss: 1.231519]\n",
      "1124 [D loss: 0.639210, acc.: 68.75%] [G loss: 1.142680]\n",
      "1125 [D loss: 0.816479, acc.: 43.75%] [G loss: 1.002594]\n",
      "1126 [D loss: 0.741507, acc.: 56.25%] [G loss: 1.239931]\n",
      "1127 [D loss: 0.609320, acc.: 65.62%] [G loss: 1.027767]\n",
      "1128 [D loss: 0.729019, acc.: 59.38%] [G loss: 1.018393]\n",
      "1129 [D loss: 0.587748, acc.: 62.50%] [G loss: 0.902831]\n",
      "1130 [D loss: 0.616959, acc.: 65.62%] [G loss: 1.131852]\n",
      "1131 [D loss: 0.693391, acc.: 59.38%] [G loss: 1.272106]\n",
      "1132 [D loss: 0.700288, acc.: 40.62%] [G loss: 1.014388]\n",
      "1133 [D loss: 0.713110, acc.: 53.12%] [G loss: 1.006838]\n",
      "1134 [D loss: 0.572762, acc.: 62.50%] [G loss: 1.088571]\n",
      "1135 [D loss: 0.710360, acc.: 53.12%] [G loss: 1.129972]\n",
      "1136 [D loss: 0.763221, acc.: 43.75%] [G loss: 1.057976]\n",
      "1137 [D loss: 0.619821, acc.: 59.38%] [G loss: 1.138209]\n",
      "1138 [D loss: 0.636676, acc.: 56.25%] [G loss: 1.172723]\n",
      "1139 [D loss: 0.624645, acc.: 62.50%] [G loss: 1.157202]\n",
      "1140 [D loss: 0.675180, acc.: 65.62%] [G loss: 0.932885]\n",
      "1141 [D loss: 0.593632, acc.: 68.75%] [G loss: 1.195242]\n",
      "1142 [D loss: 0.603961, acc.: 62.50%] [G loss: 1.084657]\n",
      "1143 [D loss: 0.733457, acc.: 53.12%] [G loss: 1.071227]\n",
      "1144 [D loss: 0.667181, acc.: 68.75%] [G loss: 0.975017]\n",
      "1145 [D loss: 0.891446, acc.: 43.75%] [G loss: 0.981683]\n",
      "1146 [D loss: 0.704776, acc.: 53.12%] [G loss: 1.039471]\n",
      "1147 [D loss: 0.664163, acc.: 71.88%] [G loss: 1.278525]\n",
      "1148 [D loss: 0.536759, acc.: 71.88%] [G loss: 1.071454]\n",
      "1149 [D loss: 0.577315, acc.: 71.88%] [G loss: 1.128982]\n",
      "1150 [D loss: 0.615599, acc.: 71.88%] [G loss: 1.062123]\n",
      "1151 [D loss: 0.618648, acc.: 68.75%] [G loss: 1.001551]\n",
      "1152 [D loss: 0.813960, acc.: 50.00%] [G loss: 1.159307]\n",
      "1153 [D loss: 0.637698, acc.: 65.62%] [G loss: 1.195180]\n",
      "1154 [D loss: 0.664640, acc.: 75.00%] [G loss: 1.079476]\n",
      "1155 [D loss: 0.560270, acc.: 68.75%] [G loss: 0.944498]\n",
      "1156 [D loss: 0.557223, acc.: 71.88%] [G loss: 1.182886]\n",
      "1157 [D loss: 0.778907, acc.: 50.00%] [G loss: 1.214143]\n",
      "1158 [D loss: 0.618631, acc.: 56.25%] [G loss: 1.088646]\n",
      "1159 [D loss: 0.654926, acc.: 68.75%] [G loss: 1.134452]\n",
      "1160 [D loss: 0.635783, acc.: 65.62%] [G loss: 0.931920]\n",
      "1161 [D loss: 0.662622, acc.: 62.50%] [G loss: 1.216895]\n",
      "1162 [D loss: 0.566676, acc.: 68.75%] [G loss: 1.505590]\n",
      "1163 [D loss: 0.795058, acc.: 56.25%] [G loss: 1.118173]\n",
      "1164 [D loss: 0.797661, acc.: 53.12%] [G loss: 0.879755]\n",
      "1165 [D loss: 0.762639, acc.: 50.00%] [G loss: 1.072203]\n",
      "1166 [D loss: 0.618666, acc.: 75.00%] [G loss: 1.080447]\n",
      "1167 [D loss: 0.488909, acc.: 84.38%] [G loss: 1.084811]\n",
      "1168 [D loss: 0.759204, acc.: 53.12%] [G loss: 0.994048]\n",
      "1169 [D loss: 0.611626, acc.: 59.38%] [G loss: 1.089910]\n",
      "1170 [D loss: 0.763182, acc.: 56.25%] [G loss: 1.173357]\n",
      "1171 [D loss: 0.665773, acc.: 56.25%] [G loss: 0.998001]\n",
      "1172 [D loss: 0.777238, acc.: 53.12%] [G loss: 1.142000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1173 [D loss: 0.756988, acc.: 50.00%] [G loss: 1.180692]\n",
      "1174 [D loss: 0.708275, acc.: 50.00%] [G loss: 1.348074]\n",
      "1175 [D loss: 0.707757, acc.: 56.25%] [G loss: 1.238021]\n",
      "1176 [D loss: 0.733870, acc.: 46.88%] [G loss: 1.242535]\n",
      "1177 [D loss: 0.738641, acc.: 56.25%] [G loss: 1.086692]\n",
      "1178 [D loss: 0.652766, acc.: 71.88%] [G loss: 1.013622]\n",
      "1179 [D loss: 0.656256, acc.: 65.62%] [G loss: 1.075988]\n",
      "1180 [D loss: 0.659312, acc.: 56.25%] [G loss: 1.220856]\n",
      "1181 [D loss: 0.784482, acc.: 46.88%] [G loss: 0.919588]\n",
      "1182 [D loss: 0.647260, acc.: 59.38%] [G loss: 1.192776]\n",
      "1183 [D loss: 0.584063, acc.: 75.00%] [G loss: 1.257545]\n",
      "1184 [D loss: 0.596215, acc.: 65.62%] [G loss: 0.978793]\n",
      "1185 [D loss: 0.748425, acc.: 46.88%] [G loss: 1.145097]\n",
      "1186 [D loss: 0.698461, acc.: 75.00%] [G loss: 1.005114]\n",
      "1187 [D loss: 0.624546, acc.: 68.75%] [G loss: 1.222661]\n",
      "1188 [D loss: 0.691765, acc.: 62.50%] [G loss: 1.042812]\n",
      "1189 [D loss: 0.554215, acc.: 78.12%] [G loss: 1.037189]\n",
      "1190 [D loss: 0.530829, acc.: 65.62%] [G loss: 0.925953]\n",
      "1191 [D loss: 0.674019, acc.: 59.38%] [G loss: 1.053178]\n",
      "1192 [D loss: 0.710806, acc.: 65.62%] [G loss: 1.043044]\n",
      "1193 [D loss: 0.692391, acc.: 53.12%] [G loss: 0.924595]\n",
      "1194 [D loss: 0.758686, acc.: 59.38%] [G loss: 1.036686]\n",
      "1195 [D loss: 0.631834, acc.: 65.62%] [G loss: 1.052682]\n",
      "1196 [D loss: 0.572692, acc.: 75.00%] [G loss: 1.279707]\n",
      "1197 [D loss: 0.691806, acc.: 62.50%] [G loss: 1.106218]\n",
      "1198 [D loss: 0.574962, acc.: 78.12%] [G loss: 0.998483]\n",
      "1199 [D loss: 0.606508, acc.: 59.38%] [G loss: 1.099734]\n",
      "1200 [D loss: 0.672176, acc.: 62.50%] [G loss: 0.987664]\n",
      "1201 [D loss: 0.670051, acc.: 53.12%] [G loss: 0.774816]\n",
      "1202 [D loss: 0.747953, acc.: 50.00%] [G loss: 1.052533]\n",
      "1203 [D loss: 0.613762, acc.: 68.75%] [G loss: 1.109825]\n",
      "1204 [D loss: 0.837224, acc.: 43.75%] [G loss: 1.076737]\n",
      "1205 [D loss: 0.712740, acc.: 53.12%] [G loss: 1.180951]\n",
      "1206 [D loss: 0.724047, acc.: 56.25%] [G loss: 1.065179]\n",
      "1207 [D loss: 0.777180, acc.: 65.62%] [G loss: 1.161721]\n",
      "1208 [D loss: 0.670869, acc.: 62.50%] [G loss: 1.073028]\n",
      "1209 [D loss: 0.881094, acc.: 28.12%] [G loss: 0.924539]\n",
      "1210 [D loss: 0.820949, acc.: 43.75%] [G loss: 1.054713]\n",
      "1211 [D loss: 0.784367, acc.: 46.88%] [G loss: 1.113740]\n",
      "1212 [D loss: 0.575739, acc.: 75.00%] [G loss: 1.038635]\n",
      "1213 [D loss: 0.674503, acc.: 59.38%] [G loss: 1.128150]\n",
      "1214 [D loss: 0.706839, acc.: 59.38%] [G loss: 1.020487]\n",
      "1215 [D loss: 0.497031, acc.: 81.25%] [G loss: 1.033323]\n",
      "1216 [D loss: 0.679912, acc.: 59.38%] [G loss: 1.068491]\n",
      "1217 [D loss: 0.662024, acc.: 59.38%] [G loss: 0.897200]\n",
      "1218 [D loss: 0.642484, acc.: 65.62%] [G loss: 1.016809]\n",
      "1219 [D loss: 0.672147, acc.: 56.25%] [G loss: 0.982616]\n",
      "1220 [D loss: 0.810431, acc.: 50.00%] [G loss: 1.106944]\n",
      "1221 [D loss: 0.575116, acc.: 68.75%] [G loss: 1.410494]\n",
      "1222 [D loss: 0.733885, acc.: 50.00%] [G loss: 1.167352]\n",
      "1223 [D loss: 0.572199, acc.: 75.00%] [G loss: 1.036737]\n",
      "1224 [D loss: 0.725341, acc.: 62.50%] [G loss: 1.074345]\n",
      "1225 [D loss: 0.694479, acc.: 50.00%] [G loss: 1.007635]\n",
      "1226 [D loss: 0.653242, acc.: 62.50%] [G loss: 0.975540]\n",
      "1227 [D loss: 0.862327, acc.: 40.62%] [G loss: 1.134205]\n",
      "1228 [D loss: 0.793735, acc.: 46.88%] [G loss: 0.926669]\n",
      "1229 [D loss: 0.653213, acc.: 62.50%] [G loss: 1.045513]\n",
      "1230 [D loss: 0.615822, acc.: 62.50%] [G loss: 1.379229]\n",
      "1231 [D loss: 0.644354, acc.: 50.00%] [G loss: 0.923494]\n",
      "1232 [D loss: 0.719895, acc.: 59.38%] [G loss: 0.970129]\n",
      "1233 [D loss: 0.637361, acc.: 59.38%] [G loss: 0.924590]\n",
      "1234 [D loss: 0.593425, acc.: 68.75%] [G loss: 0.994518]\n",
      "1235 [D loss: 0.635023, acc.: 71.88%] [G loss: 1.035970]\n",
      "1236 [D loss: 0.708893, acc.: 59.38%] [G loss: 1.027177]\n",
      "1237 [D loss: 0.537401, acc.: 68.75%] [G loss: 1.026688]\n",
      "1238 [D loss: 0.740773, acc.: 50.00%] [G loss: 1.021440]\n",
      "1239 [D loss: 0.656086, acc.: 59.38%] [G loss: 1.111254]\n",
      "1240 [D loss: 0.568121, acc.: 71.88%] [G loss: 1.046145]\n",
      "1241 [D loss: 0.691944, acc.: 56.25%] [G loss: 0.901478]\n",
      "1242 [D loss: 0.954417, acc.: 37.50%] [G loss: 1.018958]\n",
      "1243 [D loss: 0.660503, acc.: 68.75%] [G loss: 1.249515]\n",
      "1244 [D loss: 0.553248, acc.: 68.75%] [G loss: 1.188552]\n",
      "1245 [D loss: 0.931844, acc.: 37.50%] [G loss: 0.948365]\n",
      "1246 [D loss: 0.761504, acc.: 59.38%] [G loss: 1.157639]\n",
      "1247 [D loss: 0.630730, acc.: 65.62%] [G loss: 1.099361]\n",
      "1248 [D loss: 0.716888, acc.: 46.88%] [G loss: 1.066615]\n",
      "1249 [D loss: 0.637474, acc.: 62.50%] [G loss: 0.916811]\n",
      "1250 [D loss: 0.741864, acc.: 59.38%] [G loss: 0.874366]\n",
      "1251 [D loss: 0.781228, acc.: 56.25%] [G loss: 0.997818]\n",
      "1252 [D loss: 0.631396, acc.: 65.62%] [G loss: 0.872732]\n",
      "1253 [D loss: 0.719930, acc.: 56.25%] [G loss: 0.819982]\n",
      "1254 [D loss: 0.665098, acc.: 65.62%] [G loss: 1.099885]\n",
      "1255 [D loss: 0.590029, acc.: 65.62%] [G loss: 0.993747]\n",
      "1256 [D loss: 0.703424, acc.: 56.25%] [G loss: 0.827927]\n",
      "1257 [D loss: 0.725066, acc.: 50.00%] [G loss: 1.080674]\n",
      "1258 [D loss: 0.884250, acc.: 46.88%] [G loss: 0.953874]\n",
      "1259 [D loss: 0.678119, acc.: 59.38%] [G loss: 1.180711]\n",
      "1260 [D loss: 0.588294, acc.: 68.75%] [G loss: 1.009738]\n",
      "1261 [D loss: 0.632319, acc.: 65.62%] [G loss: 0.936976]\n",
      "1262 [D loss: 0.611252, acc.: 65.62%] [G loss: 0.932759]\n",
      "1263 [D loss: 0.473224, acc.: 81.25%] [G loss: 1.002689]\n",
      "1264 [D loss: 0.570670, acc.: 75.00%] [G loss: 1.128925]\n",
      "1265 [D loss: 0.659297, acc.: 59.38%] [G loss: 1.011933]\n",
      "1266 [D loss: 0.531152, acc.: 78.12%] [G loss: 0.950641]\n",
      "1267 [D loss: 0.734573, acc.: 59.38%] [G loss: 1.004039]\n",
      "1268 [D loss: 0.568523, acc.: 75.00%] [G loss: 0.977068]\n",
      "1269 [D loss: 0.626450, acc.: 56.25%] [G loss: 0.823543]\n",
      "1270 [D loss: 0.759611, acc.: 50.00%] [G loss: 0.807777]\n",
      "1271 [D loss: 0.653505, acc.: 68.75%] [G loss: 1.074646]\n",
      "1272 [D loss: 0.664855, acc.: 56.25%] [G loss: 1.130118]\n",
      "1273 [D loss: 0.639640, acc.: 68.75%] [G loss: 1.227275]\n",
      "1274 [D loss: 0.646384, acc.: 65.62%] [G loss: 1.118709]\n",
      "1275 [D loss: 0.597479, acc.: 68.75%] [G loss: 1.191143]\n",
      "1276 [D loss: 0.629538, acc.: 75.00%] [G loss: 0.970547]\n",
      "1277 [D loss: 0.677574, acc.: 62.50%] [G loss: 1.199112]\n",
      "1278 [D loss: 0.680615, acc.: 59.38%] [G loss: 1.342432]\n",
      "1279 [D loss: 0.571280, acc.: 71.88%] [G loss: 1.174228]\n",
      "1280 [D loss: 0.672125, acc.: 65.62%] [G loss: 1.030656]\n",
      "1281 [D loss: 0.593366, acc.: 71.88%] [G loss: 0.867610]\n",
      "1282 [D loss: 0.624253, acc.: 65.62%] [G loss: 0.963676]\n",
      "1283 [D loss: 0.614905, acc.: 71.88%] [G loss: 1.059527]\n",
      "1284 [D loss: 0.699080, acc.: 50.00%] [G loss: 0.738100]\n",
      "1285 [D loss: 0.824194, acc.: 46.88%] [G loss: 0.939432]\n",
      "1286 [D loss: 0.718450, acc.: 62.50%] [G loss: 0.944853]\n",
      "1287 [D loss: 0.621146, acc.: 62.50%] [G loss: 1.165373]\n",
      "1288 [D loss: 0.614898, acc.: 75.00%] [G loss: 1.079570]\n",
      "1289 [D loss: 0.603917, acc.: 71.88%] [G loss: 0.852884]\n",
      "1290 [D loss: 0.773301, acc.: 50.00%] [G loss: 1.028918]\n",
      "1291 [D loss: 0.663520, acc.: 59.38%] [G loss: 1.255303]\n",
      "1292 [D loss: 0.653171, acc.: 59.38%] [G loss: 1.109583]\n",
      "1293 [D loss: 0.703133, acc.: 62.50%] [G loss: 1.047086]\n",
      "1294 [D loss: 0.585055, acc.: 65.62%] [G loss: 0.927638]\n",
      "1295 [D loss: 0.512744, acc.: 68.75%] [G loss: 0.959590]\n",
      "1296 [D loss: 0.793680, acc.: 50.00%] [G loss: 1.185206]\n",
      "1297 [D loss: 0.700573, acc.: 56.25%] [G loss: 0.968212]\n",
      "1298 [D loss: 0.639577, acc.: 59.38%] [G loss: 1.008354]\n",
      "1299 [D loss: 0.683494, acc.: 46.88%] [G loss: 1.130980]\n",
      "1300 [D loss: 0.671442, acc.: 56.25%] [G loss: 1.342565]\n",
      "1301 [D loss: 0.593868, acc.: 71.88%] [G loss: 0.871254]\n",
      "1302 [D loss: 0.735174, acc.: 50.00%] [G loss: 1.122078]\n",
      "1303 [D loss: 0.790226, acc.: 40.62%] [G loss: 0.910243]\n",
      "1304 [D loss: 0.764983, acc.: 46.88%] [G loss: 1.131190]\n",
      "1305 [D loss: 0.735764, acc.: 62.50%] [G loss: 0.956785]\n",
      "1306 [D loss: 0.638444, acc.: 65.62%] [G loss: 1.102629]\n",
      "1307 [D loss: 0.707745, acc.: 62.50%] [G loss: 1.119163]\n",
      "1308 [D loss: 0.646256, acc.: 71.88%] [G loss: 1.127507]\n",
      "1309 [D loss: 0.708381, acc.: 59.38%] [G loss: 1.090427]\n",
      "1310 [D loss: 0.682477, acc.: 62.50%] [G loss: 0.984801]\n",
      "1311 [D loss: 0.690607, acc.: 62.50%] [G loss: 0.918382]\n",
      "1312 [D loss: 0.682706, acc.: 50.00%] [G loss: 1.061555]\n",
      "1313 [D loss: 0.875813, acc.: 43.75%] [G loss: 1.330545]\n",
      "1314 [D loss: 0.737029, acc.: 40.62%] [G loss: 1.218084]\n",
      "1315 [D loss: 0.649188, acc.: 59.38%] [G loss: 0.993272]\n",
      "1316 [D loss: 0.532744, acc.: 78.12%] [G loss: 1.257757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1317 [D loss: 0.663708, acc.: 59.38%] [G loss: 1.012346]\n",
      "1318 [D loss: 0.583135, acc.: 71.88%] [G loss: 0.868022]\n",
      "1319 [D loss: 0.620618, acc.: 62.50%] [G loss: 0.987913]\n",
      "1320 [D loss: 0.690259, acc.: 59.38%] [G loss: 1.142942]\n",
      "1321 [D loss: 0.562759, acc.: 71.88%] [G loss: 0.893162]\n",
      "1322 [D loss: 0.637482, acc.: 65.62%] [G loss: 1.078066]\n",
      "1323 [D loss: 0.496242, acc.: 71.88%] [G loss: 1.112717]\n",
      "1324 [D loss: 0.709205, acc.: 59.38%] [G loss: 0.975736]\n",
      "1325 [D loss: 0.535588, acc.: 87.50%] [G loss: 1.091727]\n",
      "1326 [D loss: 0.715416, acc.: 46.88%] [G loss: 1.314260]\n",
      "1327 [D loss: 0.568211, acc.: 71.88%] [G loss: 1.257182]\n",
      "1328 [D loss: 0.499668, acc.: 71.88%] [G loss: 1.393700]\n",
      "1329 [D loss: 0.577776, acc.: 75.00%] [G loss: 1.273915]\n",
      "1330 [D loss: 0.646627, acc.: 59.38%] [G loss: 1.245475]\n",
      "1331 [D loss: 0.658556, acc.: 59.38%] [G loss: 1.198068]\n",
      "1332 [D loss: 0.630085, acc.: 62.50%] [G loss: 0.980621]\n",
      "1333 [D loss: 0.803600, acc.: 59.38%] [G loss: 1.172945]\n",
      "1334 [D loss: 0.776702, acc.: 59.38%] [G loss: 1.074251]\n",
      "1335 [D loss: 0.914422, acc.: 37.50%] [G loss: 1.337053]\n",
      "1336 [D loss: 0.571436, acc.: 75.00%] [G loss: 1.118377]\n",
      "1337 [D loss: 0.634942, acc.: 75.00%] [G loss: 1.000258]\n",
      "1338 [D loss: 0.694757, acc.: 50.00%] [G loss: 1.103528]\n",
      "1339 [D loss: 0.621293, acc.: 62.50%] [G loss: 1.204905]\n",
      "1340 [D loss: 0.766368, acc.: 53.12%] [G loss: 1.095349]\n",
      "1341 [D loss: 0.528033, acc.: 75.00%] [G loss: 1.159619]\n",
      "1342 [D loss: 0.772294, acc.: 53.12%] [G loss: 1.075687]\n",
      "1343 [D loss: 0.704583, acc.: 53.12%] [G loss: 1.105056]\n",
      "1344 [D loss: 0.701321, acc.: 59.38%] [G loss: 0.903709]\n",
      "1345 [D loss: 0.708991, acc.: 59.38%] [G loss: 0.990259]\n",
      "1346 [D loss: 0.741399, acc.: 56.25%] [G loss: 1.139587]\n",
      "1347 [D loss: 0.606806, acc.: 62.50%] [G loss: 1.364563]\n",
      "1348 [D loss: 0.618164, acc.: 65.62%] [G loss: 1.214516]\n",
      "1349 [D loss: 0.693039, acc.: 56.25%] [G loss: 1.144670]\n",
      "1350 [D loss: 0.670560, acc.: 59.38%] [G loss: 1.197570]\n",
      "1351 [D loss: 0.623174, acc.: 68.75%] [G loss: 0.942870]\n",
      "1352 [D loss: 0.649669, acc.: 56.25%] [G loss: 0.978107]\n",
      "1353 [D loss: 0.403042, acc.: 87.50%] [G loss: 1.096202]\n",
      "1354 [D loss: 0.783418, acc.: 37.50%] [G loss: 1.027186]\n",
      "1355 [D loss: 0.766575, acc.: 43.75%] [G loss: 1.105920]\n",
      "1356 [D loss: 0.737698, acc.: 56.25%] [G loss: 1.013105]\n",
      "1357 [D loss: 0.642321, acc.: 62.50%] [G loss: 1.266019]\n",
      "1358 [D loss: 0.829717, acc.: 46.88%] [G loss: 1.314646]\n",
      "1359 [D loss: 0.723938, acc.: 46.88%] [G loss: 1.006767]\n",
      "1360 [D loss: 0.636835, acc.: 65.62%] [G loss: 0.959594]\n",
      "1361 [D loss: 0.778857, acc.: 56.25%] [G loss: 1.094718]\n",
      "1362 [D loss: 0.657355, acc.: 59.38%] [G loss: 0.997091]\n",
      "1363 [D loss: 0.643014, acc.: 62.50%] [G loss: 1.045006]\n",
      "1364 [D loss: 0.587097, acc.: 68.75%] [G loss: 1.065770]\n",
      "1365 [D loss: 0.659400, acc.: 65.62%] [G loss: 1.153503]\n",
      "1366 [D loss: 0.783204, acc.: 43.75%] [G loss: 1.045226]\n",
      "1367 [D loss: 0.716520, acc.: 56.25%] [G loss: 0.879953]\n",
      "1368 [D loss: 0.764319, acc.: 46.88%] [G loss: 0.852326]\n",
      "1369 [D loss: 0.714106, acc.: 56.25%] [G loss: 1.127041]\n",
      "1370 [D loss: 0.603401, acc.: 71.88%] [G loss: 1.214877]\n",
      "1371 [D loss: 0.661877, acc.: 65.62%] [G loss: 1.145320]\n",
      "1372 [D loss: 0.864410, acc.: 46.88%] [G loss: 0.914197]\n",
      "1373 [D loss: 0.683306, acc.: 59.38%] [G loss: 1.005803]\n",
      "1374 [D loss: 0.628101, acc.: 56.25%] [G loss: 0.954551]\n",
      "1375 [D loss: 0.644332, acc.: 59.38%] [G loss: 1.136547]\n",
      "1376 [D loss: 0.589709, acc.: 68.75%] [G loss: 1.094490]\n",
      "1377 [D loss: 0.740273, acc.: 43.75%] [G loss: 1.140767]\n",
      "1378 [D loss: 0.713750, acc.: 56.25%] [G loss: 1.161129]\n",
      "1379 [D loss: 0.631855, acc.: 68.75%] [G loss: 1.111512]\n",
      "1380 [D loss: 0.810325, acc.: 46.88%] [G loss: 1.025302]\n",
      "1381 [D loss: 0.673185, acc.: 68.75%] [G loss: 0.834098]\n",
      "1382 [D loss: 0.621221, acc.: 59.38%] [G loss: 0.910514]\n",
      "1383 [D loss: 0.650126, acc.: 59.38%] [G loss: 1.004505]\n",
      "1384 [D loss: 0.654214, acc.: 53.12%] [G loss: 1.244496]\n",
      "1385 [D loss: 0.719318, acc.: 62.50%] [G loss: 1.117048]\n",
      "1386 [D loss: 0.722285, acc.: 50.00%] [G loss: 0.959718]\n",
      "1387 [D loss: 0.733072, acc.: 53.12%] [G loss: 0.827793]\n",
      "1388 [D loss: 0.566971, acc.: 75.00%] [G loss: 1.173414]\n",
      "1389 [D loss: 0.668404, acc.: 56.25%] [G loss: 0.952061]\n",
      "1390 [D loss: 0.752923, acc.: 59.38%] [G loss: 0.944919]\n",
      "1391 [D loss: 0.735063, acc.: 62.50%] [G loss: 1.119992]\n",
      "1392 [D loss: 0.636313, acc.: 71.88%] [G loss: 0.960179]\n",
      "1393 [D loss: 0.699576, acc.: 62.50%] [G loss: 0.932818]\n",
      "1394 [D loss: 0.756064, acc.: 37.50%] [G loss: 1.007722]\n",
      "1395 [D loss: 0.843245, acc.: 46.88%] [G loss: 1.131663]\n",
      "1396 [D loss: 0.517272, acc.: 78.12%] [G loss: 1.124375]\n",
      "1397 [D loss: 0.842292, acc.: 53.12%] [G loss: 1.092946]\n",
      "1398 [D loss: 0.675435, acc.: 50.00%] [G loss: 1.172126]\n",
      "1399 [D loss: 0.709289, acc.: 56.25%] [G loss: 1.115169]\n",
      "1400 [D loss: 0.879925, acc.: 40.62%] [G loss: 1.130797]\n",
      "1401 [D loss: 0.622218, acc.: 59.38%] [G loss: 0.869629]\n",
      "1402 [D loss: 0.621605, acc.: 65.62%] [G loss: 0.806309]\n",
      "1403 [D loss: 0.739818, acc.: 56.25%] [G loss: 0.993979]\n",
      "1404 [D loss: 0.820314, acc.: 43.75%] [G loss: 0.889576]\n",
      "1405 [D loss: 0.557898, acc.: 68.75%] [G loss: 1.051451]\n",
      "1406 [D loss: 0.594669, acc.: 65.62%] [G loss: 1.146560]\n",
      "1407 [D loss: 0.508263, acc.: 84.38%] [G loss: 0.977776]\n",
      "1408 [D loss: 0.633924, acc.: 59.38%] [G loss: 0.925157]\n",
      "1409 [D loss: 0.646850, acc.: 62.50%] [G loss: 1.066174]\n",
      "1410 [D loss: 0.492337, acc.: 87.50%] [G loss: 0.909037]\n",
      "1411 [D loss: 0.697125, acc.: 59.38%] [G loss: 1.011363]\n",
      "1412 [D loss: 0.732370, acc.: 56.25%] [G loss: 1.021825]\n",
      "1413 [D loss: 0.568352, acc.: 78.12%] [G loss: 1.154834]\n",
      "1414 [D loss: 0.640656, acc.: 62.50%] [G loss: 1.132507]\n",
      "1415 [D loss: 0.781136, acc.: 46.88%] [G loss: 0.975339]\n",
      "1416 [D loss: 0.671366, acc.: 56.25%] [G loss: 1.112630]\n",
      "1417 [D loss: 0.596720, acc.: 65.62%] [G loss: 1.094349]\n",
      "1418 [D loss: 0.678456, acc.: 62.50%] [G loss: 1.035141]\n",
      "1419 [D loss: 0.779512, acc.: 53.12%] [G loss: 1.213974]\n",
      "1420 [D loss: 0.622855, acc.: 62.50%] [G loss: 0.973104]\n",
      "1421 [D loss: 0.579841, acc.: 65.62%] [G loss: 1.016252]\n",
      "1422 [D loss: 0.669927, acc.: 62.50%] [G loss: 1.306608]\n",
      "1423 [D loss: 0.806512, acc.: 62.50%] [G loss: 1.200405]\n",
      "1424 [D loss: 0.733255, acc.: 53.12%] [G loss: 1.150744]\n",
      "1425 [D loss: 0.613590, acc.: 71.88%] [G loss: 1.117770]\n",
      "1426 [D loss: 0.556376, acc.: 75.00%] [G loss: 1.163803]\n",
      "1427 [D loss: 0.664633, acc.: 62.50%] [G loss: 1.116717]\n",
      "1428 [D loss: 0.737780, acc.: 50.00%] [G loss: 0.821312]\n",
      "1429 [D loss: 0.647147, acc.: 50.00%] [G loss: 0.918466]\n",
      "1430 [D loss: 0.718189, acc.: 56.25%] [G loss: 0.982137]\n",
      "1431 [D loss: 0.611792, acc.: 59.38%] [G loss: 0.914398]\n",
      "1432 [D loss: 0.764583, acc.: 50.00%] [G loss: 1.016185]\n",
      "1433 [D loss: 0.718921, acc.: 65.62%] [G loss: 0.932196]\n",
      "1434 [D loss: 0.717857, acc.: 53.12%] [G loss: 1.182269]\n",
      "1435 [D loss: 0.759512, acc.: 46.88%] [G loss: 0.933866]\n",
      "1436 [D loss: 0.792875, acc.: 37.50%] [G loss: 0.892191]\n",
      "1437 [D loss: 0.644073, acc.: 56.25%] [G loss: 0.783038]\n",
      "1438 [D loss: 0.660982, acc.: 56.25%] [G loss: 1.089603]\n",
      "1439 [D loss: 0.705124, acc.: 56.25%] [G loss: 1.228255]\n",
      "1440 [D loss: 0.796438, acc.: 46.88%] [G loss: 1.144701]\n",
      "1441 [D loss: 0.721646, acc.: 56.25%] [G loss: 0.962074]\n",
      "1442 [D loss: 0.680889, acc.: 62.50%] [G loss: 0.957958]\n",
      "1443 [D loss: 0.653437, acc.: 59.38%] [G loss: 1.054421]\n",
      "1444 [D loss: 0.454003, acc.: 81.25%] [G loss: 1.047670]\n",
      "1445 [D loss: 0.716621, acc.: 53.12%] [G loss: 0.933441]\n",
      "1446 [D loss: 0.766539, acc.: 46.88%] [G loss: 0.872444]\n",
      "1447 [D loss: 0.721640, acc.: 65.62%] [G loss: 0.882112]\n",
      "1448 [D loss: 0.620229, acc.: 62.50%] [G loss: 1.087704]\n",
      "1449 [D loss: 0.686797, acc.: 53.12%] [G loss: 1.112696]\n",
      "1450 [D loss: 0.726725, acc.: 56.25%] [G loss: 1.079327]\n",
      "1451 [D loss: 0.636662, acc.: 59.38%] [G loss: 0.941323]\n",
      "1452 [D loss: 0.644225, acc.: 68.75%] [G loss: 0.889661]\n",
      "1453 [D loss: 0.561909, acc.: 78.12%] [G loss: 1.119360]\n",
      "1454 [D loss: 0.635523, acc.: 59.38%] [G loss: 1.029628]\n",
      "1455 [D loss: 0.580780, acc.: 71.88%] [G loss: 0.989595]\n",
      "1456 [D loss: 0.656009, acc.: 59.38%] [G loss: 1.220184]\n",
      "1457 [D loss: 0.620685, acc.: 59.38%] [G loss: 1.051127]\n",
      "1458 [D loss: 0.656847, acc.: 59.38%] [G loss: 0.878623]\n",
      "1459 [D loss: 0.769996, acc.: 46.88%] [G loss: 0.892107]\n",
      "1460 [D loss: 0.800944, acc.: 43.75%] [G loss: 1.086621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461 [D loss: 0.719984, acc.: 50.00%] [G loss: 0.941196]\n",
      "1462 [D loss: 0.679999, acc.: 65.62%] [G loss: 1.088877]\n",
      "1463 [D loss: 0.662072, acc.: 65.62%] [G loss: 1.124354]\n",
      "1464 [D loss: 0.815345, acc.: 46.88%] [G loss: 1.117188]\n",
      "1465 [D loss: 0.727572, acc.: 71.88%] [G loss: 1.046385]\n",
      "1466 [D loss: 0.565830, acc.: 71.88%] [G loss: 0.972116]\n",
      "1467 [D loss: 0.705380, acc.: 59.38%] [G loss: 1.032201]\n",
      "1468 [D loss: 0.745711, acc.: 50.00%] [G loss: 1.201559]\n",
      "1469 [D loss: 0.671414, acc.: 65.62%] [G loss: 1.250131]\n",
      "1470 [D loss: 0.636559, acc.: 62.50%] [G loss: 1.189504]\n",
      "1471 [D loss: 0.742401, acc.: 56.25%] [G loss: 1.177509]\n",
      "1472 [D loss: 0.688032, acc.: 53.12%] [G loss: 1.116601]\n",
      "1473 [D loss: 0.696512, acc.: 65.62%] [G loss: 1.016150]\n",
      "1474 [D loss: 0.564718, acc.: 71.88%] [G loss: 1.240003]\n",
      "1475 [D loss: 0.769575, acc.: 50.00%] [G loss: 0.968294]\n",
      "1476 [D loss: 0.544344, acc.: 78.12%] [G loss: 0.987717]\n",
      "1477 [D loss: 0.605820, acc.: 68.75%] [G loss: 0.890529]\n",
      "1478 [D loss: 0.729276, acc.: 53.12%] [G loss: 0.878050]\n",
      "1479 [D loss: 0.685598, acc.: 59.38%] [G loss: 0.904378]\n",
      "1480 [D loss: 0.735499, acc.: 59.38%] [G loss: 0.934824]\n",
      "1481 [D loss: 0.848877, acc.: 40.62%] [G loss: 0.956185]\n",
      "1482 [D loss: 0.589113, acc.: 65.62%] [G loss: 0.990964]\n",
      "1483 [D loss: 0.677947, acc.: 53.12%] [G loss: 0.907380]\n",
      "1484 [D loss: 0.742041, acc.: 59.38%] [G loss: 1.076158]\n",
      "1485 [D loss: 0.751397, acc.: 56.25%] [G loss: 1.046703]\n",
      "1486 [D loss: 0.770588, acc.: 43.75%] [G loss: 0.932451]\n",
      "1487 [D loss: 0.622253, acc.: 62.50%] [G loss: 1.165998]\n",
      "1488 [D loss: 0.683201, acc.: 59.38%] [G loss: 1.034545]\n",
      "1489 [D loss: 0.534253, acc.: 75.00%] [G loss: 1.146462]\n",
      "1490 [D loss: 0.840987, acc.: 50.00%] [G loss: 1.065961]\n",
      "1491 [D loss: 0.845334, acc.: 31.25%] [G loss: 0.860144]\n",
      "1492 [D loss: 0.584333, acc.: 62.50%] [G loss: 1.070058]\n",
      "1493 [D loss: 0.763497, acc.: 50.00%] [G loss: 0.784328]\n",
      "1494 [D loss: 0.678381, acc.: 62.50%] [G loss: 0.958816]\n",
      "1495 [D loss: 0.584928, acc.: 68.75%] [G loss: 1.093611]\n",
      "1496 [D loss: 0.560375, acc.: 65.62%] [G loss: 0.745134]\n",
      "1497 [D loss: 0.648513, acc.: 68.75%] [G loss: 1.129539]\n",
      "1498 [D loss: 0.684177, acc.: 56.25%] [G loss: 1.130679]\n",
      "1499 [D loss: 0.679140, acc.: 56.25%] [G loss: 1.228102]\n",
      "1500 [D loss: 0.445616, acc.: 81.25%] [G loss: 0.972791]\n",
      "1501 [D loss: 0.598036, acc.: 65.62%] [G loss: 0.972156]\n",
      "1502 [D loss: 0.634699, acc.: 59.38%] [G loss: 0.953782]\n",
      "1503 [D loss: 0.575483, acc.: 62.50%] [G loss: 0.910324]\n",
      "1504 [D loss: 0.657535, acc.: 62.50%] [G loss: 0.879420]\n",
      "1505 [D loss: 0.638370, acc.: 71.88%] [G loss: 0.888161]\n",
      "1506 [D loss: 0.843195, acc.: 40.62%] [G loss: 1.025848]\n",
      "1507 [D loss: 0.734353, acc.: 53.12%] [G loss: 1.131076]\n",
      "1508 [D loss: 0.876480, acc.: 34.38%] [G loss: 1.047886]\n",
      "1509 [D loss: 0.676291, acc.: 50.00%] [G loss: 1.035030]\n",
      "1510 [D loss: 0.687858, acc.: 59.38%] [G loss: 1.007335]\n",
      "1511 [D loss: 0.643587, acc.: 62.50%] [G loss: 1.114346]\n",
      "1512 [D loss: 0.649899, acc.: 62.50%] [G loss: 1.032052]\n",
      "1513 [D loss: 0.732958, acc.: 56.25%] [G loss: 1.070440]\n",
      "1514 [D loss: 0.688666, acc.: 59.38%] [G loss: 1.301899]\n",
      "1515 [D loss: 0.699415, acc.: 43.75%] [G loss: 1.243005]\n",
      "1516 [D loss: 0.669250, acc.: 56.25%] [G loss: 1.199136]\n",
      "1517 [D loss: 0.916980, acc.: 28.12%] [G loss: 1.093854]\n",
      "1518 [D loss: 0.838248, acc.: 56.25%] [G loss: 1.015665]\n",
      "1519 [D loss: 0.662205, acc.: 59.38%] [G loss: 1.013757]\n",
      "1520 [D loss: 0.644970, acc.: 59.38%] [G loss: 1.098820]\n",
      "1521 [D loss: 0.603494, acc.: 68.75%] [G loss: 1.059142]\n",
      "1522 [D loss: 0.738247, acc.: 53.12%] [G loss: 1.109242]\n",
      "1523 [D loss: 0.733139, acc.: 56.25%] [G loss: 1.013441]\n",
      "1524 [D loss: 0.645673, acc.: 53.12%] [G loss: 1.091689]\n",
      "1525 [D loss: 0.609327, acc.: 68.75%] [G loss: 1.250219]\n",
      "1526 [D loss: 0.696838, acc.: 56.25%] [G loss: 1.063597]\n",
      "1527 [D loss: 0.631764, acc.: 65.62%] [G loss: 0.959740]\n",
      "1528 [D loss: 0.548037, acc.: 68.75%] [G loss: 0.940020]\n",
      "1529 [D loss: 0.605085, acc.: 65.62%] [G loss: 0.922058]\n",
      "1530 [D loss: 0.578190, acc.: 81.25%] [G loss: 0.934841]\n",
      "1531 [D loss: 0.665542, acc.: 62.50%] [G loss: 0.849010]\n",
      "1532 [D loss: 0.809684, acc.: 37.50%] [G loss: 0.754089]\n",
      "1533 [D loss: 0.667809, acc.: 53.12%] [G loss: 0.921140]\n",
      "1534 [D loss: 0.714404, acc.: 59.38%] [G loss: 0.867167]\n",
      "1535 [D loss: 0.834913, acc.: 43.75%] [G loss: 1.117678]\n",
      "1536 [D loss: 0.667861, acc.: 68.75%] [G loss: 1.216596]\n",
      "1537 [D loss: 0.611495, acc.: 68.75%] [G loss: 1.066211]\n",
      "1538 [D loss: 0.547076, acc.: 75.00%] [G loss: 1.122124]\n",
      "1539 [D loss: 0.733183, acc.: 50.00%] [G loss: 1.225665]\n",
      "1540 [D loss: 0.791449, acc.: 43.75%] [G loss: 0.882924]\n",
      "1541 [D loss: 0.674312, acc.: 62.50%] [G loss: 0.971953]\n",
      "1542 [D loss: 0.808097, acc.: 50.00%] [G loss: 1.250423]\n",
      "1543 [D loss: 0.731203, acc.: 62.50%] [G loss: 1.290309]\n",
      "1544 [D loss: 0.661211, acc.: 59.38%] [G loss: 1.057997]\n",
      "1545 [D loss: 0.578066, acc.: 65.62%] [G loss: 1.039711]\n",
      "1546 [D loss: 0.825640, acc.: 46.88%] [G loss: 1.016619]\n",
      "1547 [D loss: 0.740534, acc.: 53.12%] [G loss: 1.015411]\n",
      "1548 [D loss: 0.825930, acc.: 46.88%] [G loss: 0.911666]\n",
      "1549 [D loss: 0.571851, acc.: 71.88%] [G loss: 1.012137]\n",
      "1550 [D loss: 0.591341, acc.: 65.62%] [G loss: 1.022539]\n",
      "1551 [D loss: 0.614603, acc.: 65.62%] [G loss: 1.151387]\n",
      "1552 [D loss: 0.734842, acc.: 53.12%] [G loss: 1.164056]\n",
      "1553 [D loss: 0.675899, acc.: 53.12%] [G loss: 1.206825]\n",
      "1554 [D loss: 0.554594, acc.: 68.75%] [G loss: 0.934197]\n",
      "1555 [D loss: 0.646108, acc.: 53.12%] [G loss: 0.962168]\n",
      "1556 [D loss: 0.654443, acc.: 68.75%] [G loss: 1.131612]\n",
      "1557 [D loss: 0.720721, acc.: 59.38%] [G loss: 1.065983]\n",
      "1558 [D loss: 0.839475, acc.: 50.00%] [G loss: 1.144786]\n",
      "1559 [D loss: 0.840682, acc.: 46.88%] [G loss: 1.033097]\n",
      "1560 [D loss: 0.532787, acc.: 78.12%] [G loss: 1.157327]\n",
      "1561 [D loss: 0.775022, acc.: 46.88%] [G loss: 0.942467]\n",
      "1562 [D loss: 0.717251, acc.: 56.25%] [G loss: 1.102237]\n",
      "1563 [D loss: 0.677499, acc.: 62.50%] [G loss: 1.093274]\n",
      "1564 [D loss: 0.621684, acc.: 62.50%] [G loss: 1.192466]\n",
      "1565 [D loss: 0.633267, acc.: 65.62%] [G loss: 1.058469]\n",
      "1566 [D loss: 0.650935, acc.: 59.38%] [G loss: 1.224103]\n",
      "1567 [D loss: 0.623881, acc.: 62.50%] [G loss: 1.142495]\n",
      "1568 [D loss: 0.557392, acc.: 78.12%] [G loss: 1.124743]\n",
      "1569 [D loss: 0.722867, acc.: 56.25%] [G loss: 1.187189]\n",
      "1570 [D loss: 0.624632, acc.: 59.38%] [G loss: 1.124323]\n",
      "1571 [D loss: 0.649224, acc.: 56.25%] [G loss: 0.961150]\n",
      "1572 [D loss: 0.560861, acc.: 71.88%] [G loss: 0.983307]\n",
      "1573 [D loss: 0.654839, acc.: 62.50%] [G loss: 1.127189]\n",
      "1574 [D loss: 0.602602, acc.: 68.75%] [G loss: 1.066745]\n",
      "1575 [D loss: 0.686048, acc.: 56.25%] [G loss: 0.911849]\n",
      "1576 [D loss: 0.657967, acc.: 62.50%] [G loss: 1.063432]\n",
      "1577 [D loss: 0.624731, acc.: 65.62%] [G loss: 1.079989]\n",
      "1578 [D loss: 0.744686, acc.: 59.38%] [G loss: 1.060537]\n",
      "1579 [D loss: 0.621553, acc.: 68.75%] [G loss: 1.072636]\n",
      "1580 [D loss: 0.984564, acc.: 40.62%] [G loss: 0.937506]\n",
      "1581 [D loss: 0.655636, acc.: 71.88%] [G loss: 0.814034]\n",
      "1582 [D loss: 0.774064, acc.: 43.75%] [G loss: 0.865890]\n",
      "1583 [D loss: 0.743586, acc.: 50.00%] [G loss: 0.976462]\n",
      "1584 [D loss: 0.618398, acc.: 62.50%] [G loss: 0.971282]\n",
      "1585 [D loss: 0.532454, acc.: 81.25%] [G loss: 0.937593]\n",
      "1586 [D loss: 0.607374, acc.: 68.75%] [G loss: 0.864605]\n",
      "1587 [D loss: 0.643544, acc.: 56.25%] [G loss: 0.975695]\n",
      "1588 [D loss: 0.639835, acc.: 71.88%] [G loss: 1.129291]\n",
      "1589 [D loss: 0.713002, acc.: 50.00%] [G loss: 1.000467]\n",
      "1590 [D loss: 0.825262, acc.: 40.62%] [G loss: 0.967629]\n",
      "1591 [D loss: 0.758971, acc.: 53.12%] [G loss: 0.938382]\n",
      "1592 [D loss: 0.534300, acc.: 75.00%] [G loss: 1.022620]\n",
      "1593 [D loss: 0.694006, acc.: 46.88%] [G loss: 1.071786]\n",
      "1594 [D loss: 0.555139, acc.: 75.00%] [G loss: 1.071429]\n",
      "1595 [D loss: 0.616680, acc.: 71.88%] [G loss: 1.027295]\n",
      "1596 [D loss: 0.714012, acc.: 56.25%] [G loss: 0.979622]\n",
      "1597 [D loss: 0.685250, acc.: 56.25%] [G loss: 1.085204]\n",
      "1598 [D loss: 0.864340, acc.: 31.25%] [G loss: 0.965880]\n",
      "1599 [D loss: 0.700751, acc.: 62.50%] [G loss: 0.911074]\n",
      "1600 [D loss: 0.657991, acc.: 56.25%] [G loss: 1.191483]\n",
      "1601 [D loss: 0.647634, acc.: 65.62%] [G loss: 1.107160]\n",
      "1602 [D loss: 0.572751, acc.: 62.50%] [G loss: 1.135715]\n",
      "1603 [D loss: 0.528900, acc.: 71.88%] [G loss: 1.124972]\n",
      "1604 [D loss: 0.530737, acc.: 84.38%] [G loss: 1.224552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1605 [D loss: 0.804124, acc.: 50.00%] [G loss: 1.024778]\n",
      "1606 [D loss: 0.831486, acc.: 46.88%] [G loss: 1.124093]\n",
      "1607 [D loss: 0.559210, acc.: 68.75%] [G loss: 1.035478]\n",
      "1608 [D loss: 0.705123, acc.: 59.38%] [G loss: 1.069409]\n",
      "1609 [D loss: 0.633014, acc.: 56.25%] [G loss: 1.004148]\n",
      "1610 [D loss: 0.652551, acc.: 59.38%] [G loss: 0.900982]\n",
      "1611 [D loss: 0.658405, acc.: 56.25%] [G loss: 1.066358]\n",
      "1612 [D loss: 0.666789, acc.: 62.50%] [G loss: 1.129076]\n",
      "1613 [D loss: 0.716405, acc.: 50.00%] [G loss: 1.068013]\n",
      "1614 [D loss: 0.675274, acc.: 62.50%] [G loss: 0.931964]\n",
      "1615 [D loss: 0.786124, acc.: 50.00%] [G loss: 1.070537]\n",
      "1616 [D loss: 0.701361, acc.: 62.50%] [G loss: 1.030697]\n",
      "1617 [D loss: 0.724866, acc.: 59.38%] [G loss: 1.171723]\n",
      "1618 [D loss: 0.675537, acc.: 53.12%] [G loss: 1.120259]\n",
      "1619 [D loss: 0.789362, acc.: 59.38%] [G loss: 0.989810]\n",
      "1620 [D loss: 0.592753, acc.: 65.62%] [G loss: 1.042818]\n",
      "1621 [D loss: 0.764827, acc.: 50.00%] [G loss: 1.030154]\n",
      "1622 [D loss: 0.763425, acc.: 43.75%] [G loss: 0.870142]\n",
      "1623 [D loss: 0.655174, acc.: 56.25%] [G loss: 0.887119]\n",
      "1624 [D loss: 0.626478, acc.: 65.62%] [G loss: 0.733574]\n",
      "1625 [D loss: 0.709278, acc.: 46.88%] [G loss: 0.959887]\n",
      "1626 [D loss: 0.652581, acc.: 56.25%] [G loss: 0.873989]\n",
      "1627 [D loss: 0.633652, acc.: 62.50%] [G loss: 0.934377]\n",
      "1628 [D loss: 0.646958, acc.: 62.50%] [G loss: 0.946827]\n",
      "1629 [D loss: 0.683180, acc.: 59.38%] [G loss: 1.052944]\n",
      "1630 [D loss: 0.701388, acc.: 59.38%] [G loss: 0.882865]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    train(epochs=4000, batch_size=32, save_interval=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The output:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \" https://lh5.googleusercontent.com/fkIorDIqqOWoG5r1k2Vhiq2P5tUvZgWSHu7oFrUtpLZAyX6V-Xtqw4nPQCuInCEoHXJV0KBkLoycdTgqeySg=w1884-h1830-rw\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
